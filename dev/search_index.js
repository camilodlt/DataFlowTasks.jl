var documenterSearchIndex = {"docs":
[{"location":"references/#references-section","page":"References","title":"References","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"Modules = [DataFlowTasks, GraphViz_Ext, Makie_Ext]","category":"page"},{"location":"references/#DataFlowTasks.DataFlowTasks","page":"References","title":"DataFlowTasks.DataFlowTasks","text":"module DataFlowTask\n\nCreate Tasks which can keep track of how data flows through it.\n\n\n\n\n\n","category":"module"},{"location":"references/#DataFlowTasks.LOGINFO","page":"References","title":"DataFlowTasks.LOGINFO","text":"const LOGINFO::Ref{LogInfo}\n\nGlobal LogInfo being used to record the events. Can be changed using _setloginfo!.\n\n\n\n\n\n","category":"constant"},{"location":"references/#DataFlowTasks.TASKCOUNTER","page":"References","title":"DataFlowTasks.TASKCOUNTER","text":"const TASKCOUNTER::Threads.Atomic{Int64}\n\nGlobal counter of created DataFlowTasks.\n\n\n\n\n\n","category":"constant"},{"location":"references/#DataFlowTasks.TASKGRAPH","page":"References","title":"DataFlowTasks.TASKGRAPH","text":"const TASKGRAPH::Ref{TASKGRAPH}\n\nThe active TaskGraph being used. Nodes will be added to this TaskGraph by default.\n\nCan be changed using set_active_taskgraph!.\n\n\n\n\n\n","category":"constant"},{"location":"references/#DataFlowTasks.AccessMode","page":"References","title":"DataFlowTasks.AccessMode","text":"@enum AccessMode READ WRITE READWRITE\n\nDescribe how a DataFlowTask access its data.\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.DAG","page":"References","title":"DataFlowTasks.DAG","text":"struct DAG{T}\n\nRepresentation of a directed acyclic graph containing nodes of type T. The list of nodes with edges coming into a node i can be retrieved using inneighbors(dag,i); similarly, the list of nodes with edges leaving from i can be retrieved using outneighbors(dag,i).\n\nDAG is a buffered structure with a buffer of size sz_max: calling addnode! on it will block if the DAG has more than sz_max elements.\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.DAG-Union{Tuple{}, Tuple{Any}, Tuple{T}} where T","page":"References","title":"DataFlowTasks.DAG","text":"DAG{T}(sz)\n\nCreate a buffered DAG holding a maximum of sz nodes of type T.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.DataFlowTask","page":"References","title":"DataFlowTasks.DataFlowTask","text":"DataFlowTask(func,data,mode)\n\nCreate a task-like object similar to Task(func) which accesses data with AccessMode mode.\n\nWhen a DataFlowTask is created, the elements in its data field will be checked against all other active DataFlowTask to determined if a dependency is present based on a data-flow analysis. The resulting Task will then wait on those dependencies.\n\nA DataFlowTask behaves much like a Julia Task: you can call wait(t), schedule(t) and fetch(t) on it.\n\nSee also: @dtask, @dspawn, @dasync.\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.FinishedChannel","page":"References","title":"DataFlowTasks.FinishedChannel","text":"struct FinishedChannel{T} <: AbstractChannel{T}\n\nUsed to store tasks which have been completed, but not yet removed from the underlying DAG. Taking from an empty FinishedChannel will block.\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.InsertionLog","page":"References","title":"DataFlowTasks.InsertionLog","text":"struct InsertionLog\n\nLogs the execution trace of a DataFlowTask insertion.\n\nFields:\n\ntime_start  : time the insertion began\ntime_finish : time the insertion finished\ntaskid      : the task it is inserting\ntid         : the thread on which the insertion is happening\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.LogInfo","page":"References","title":"DataFlowTasks.LogInfo","text":"struct LogInfo\n\nContains informations on the program's progress. For thread-safety, the LogInfo structure uses one vector of TaskLog per thread.\n\nYou can visualize and postprocess a LogInfo using GraphViz.Graph and Makie.plot.\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.Stop","page":"References","title":"DataFlowTasks.Stop","text":"struct Stop\n\nSingleton type used to safely interrupt a task reading from an AbstractChannel.\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.TaskGraph","page":"References","title":"DataFlowTasks.TaskGraph","text":"struct TaskGraph\n\nA directed acyclic graph used to reprenset the dependencies between DataFlowTasks.\n\nTaskGraph(sz) creates a task graph that can hold at most sz elements at any given time. In particular, trying to add a new DataFlowTask will block if the TaskGraph is already full.\n\nSee also: get_active_taskgraph, set_active_taskgraph!\n\n\n\n\n\n","category":"type"},{"location":"references/#DataFlowTasks.TaskLog","page":"References","title":"DataFlowTasks.TaskLog","text":"struct TaskLog\n\nLogs the execution trace of a DataFlowTask.\n\nFields:\n\ntag         : task id in DAG\ntime_start  : time the task started running\ntime_finish : time the task finished running\ntid         : thread on which the task ran\ninneighbors : vector of incoming neighbors in DAG\nlabel       : a string used for displaying and/or postprocessing tasks\n\n\n\n\n\n","category":"type"},{"location":"references/#Base.empty!-Tuple{DataFlowTasks.TaskGraph}","page":"References","title":"Base.empty!","text":"empty!(tg::TaskGraph)\n\nInterrupt all tasks in tg and remove them from the underlying DAG.\n\nThis function is useful to avoid having to restart the REPL when a task in tg errors.\n\n\n\n\n\n","category":"method"},{"location":"references/#Base.resize!-Tuple{DataFlowTasks.TaskGraph, Any}","page":"References","title":"Base.resize!","text":"resize!(tg::TaskGraph, sz)\n\nChange the buffer size of tg to sz.\n\n\n\n\n\n","category":"method"},{"location":"references/#Base.wait-Tuple{DataFlowTasks.TaskGraph}","page":"References","title":"Base.wait","text":"wait(tg::TaskGraph)\n\nWait for all nodes in tg to be finished before continuining.\n\nTo wait on the active TaskGraph, use wait(get_active_taskgraph()).\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks._getloginfo-Tuple{}","page":"References","title":"DataFlowTasks._getloginfo","text":"_getloginfo()\n\nReturn the active logger.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks._setloginfo!-Tuple{Union{Nothing, DataFlowTasks.LogInfo}}","page":"References","title":"DataFlowTasks._setloginfo!","text":"_setloginfo!(l::LogInfo)\n\nSet the active logger to l.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.access_mode-Tuple{DataFlowTasks.DataFlowTask}","page":"References","title":"DataFlowTasks.access_mode","text":"access_mode(t::DataFlowTask[,i])\n\nHow t accesses its data.\n\nSee: AccessMode\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.addedge!-Union{Tuple{T}, Tuple{DataFlowTasks.DAG{T}, T, T}} where T","page":"References","title":"DataFlowTasks.addedge!","text":"addedge!(dag,i,j)\n\nAdd (directed) edge connecting node i to node j in the dag.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.addedge_transitive!-Tuple{Any, Any, Any}","page":"References","title":"DataFlowTasks.addedge_transitive!","text":"addedge_transitive!(dag,i,j)\n\nAdd edge connecting nodes i and j if there is no path connecting them already.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.addnode!-Union{Tuple{T}, Tuple{DataFlowTasks.DAG{T}, T}, Tuple{DataFlowTasks.DAG{T}, T, Any}} where T","page":"References","title":"DataFlowTasks.addnode!","text":"addnode!(dag,(k,v)::Pair[, check=false])\naddnode!(dag,k[, check=false])\n\nAdd a node to the dag. If passed only a key k, the value v is initialized as empty (no edges added). The check flag is used to indicate if a data flow analysis should be performed to update the dependencies of the newly inserted node.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.capacity-Tuple{DataFlowTasks.DAG}","page":"References","title":"DataFlowTasks.capacity","text":"capacity(dag)\n\nThe maximum number of nodes that dag can contain.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.data-Tuple{DataFlowTasks.DataFlowTask}","page":"References","title":"DataFlowTasks.data","text":"data(t::DataFlowTask[,i])\n\nData accessed by t.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.data_dependency-Tuple{DataFlowTasks.DataFlowTask, DataFlowTasks.DataFlowTask}","page":"References","title":"DataFlowTasks.data_dependency","text":"data_dependency(t1::DataFlowTask,t1::DataFlowTask)\n\nDetermines if there is a data dependency between t1 and t2 based on the data they read from and write to.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.describe-Tuple{DataFlowTasks.LogInfo}","page":"References","title":"DataFlowTasks.describe","text":"describe(loginfo::LogInfo; categories = String[])\ndescribe(io, loginfo::LogInfo; categories = String[])\n\nAnalyses the information contained in loginfo and displays a summary on io (stdout by default).\n\nPassing a categories argument allows grouping tasks by category. The categories can be a vector of Strings or a vector of String => Regex pairs, which will be matched against the tasks' labels.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.enable_debug","page":"References","title":"DataFlowTasks.enable_debug","text":"enable_debug(mode = true)\n\nIf mode is true (the default), enable debug mode: errors inside tasks will be shown.\n\n\n\n\n\n","category":"function"},{"location":"references/#DataFlowTasks.enable_log","page":"References","title":"DataFlowTasks.enable_log","text":"enable_log(mode = true)\n\nIf mode is true (the default), logging is enabled throug the @log macro. Calling enable_log(false) will de-activate logging at compile time to avoid any possible overhead.\n\nNote that changing the log mode at runtime will may invalidate code, possibly triggering recompilation.\n\nSee also: @log, with_logging\n\n\n\n\n\n","category":"function"},{"location":"references/#DataFlowTasks.force_linear_dag","page":"References","title":"DataFlowTasks.force_linear_dag","text":"force_linear_dag(mode=false)\n\nIf mode is true, nodes are added to the DAG in a linear fashion, i.e. the DAG connects node i to node i+1. This is useful for debugging purposes.\n\n\n\n\n\n","category":"function"},{"location":"references/#DataFlowTasks.force_sequential","page":"References","title":"DataFlowTasks.force_sequential","text":"force_sequential(mode = true)\n\nIf mode is true, enable sequential mode: no tasks are created and scheduled, code is simply run as it appears in the sources. In effect, this makes @dspawn a no-op.\n\nBy default, sequential mode is disabled when the program starts.\n\nSee also: force_linear_dag.\n\n\n\n\n\n","category":"function"},{"location":"references/#DataFlowTasks.get_active_taskgraph-Tuple{}","page":"References","title":"DataFlowTasks.get_active_taskgraph","text":"get_active_taskgraph()\n\nReturn the active TaskGraph.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.has_edge-Tuple{DataFlowTasks.DAG, Any, Any}","page":"References","title":"DataFlowTasks.has_edge","text":"has_edge(dag,i,j)\n\nCheck if there is an edge connecting i to j.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.inneighbors-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.inneighbors","text":"inneighbors(dag,i)\n\nList of predecessors of i in dag.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.isconnected-Tuple{DataFlowTasks.DAG, Any, Any}","page":"References","title":"DataFlowTasks.isconnected","text":"isconnected(dag,i,j)\n\nCheck if there is a path in dag connecting i to j.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.memory_overlap-Tuple{Any, Any}","page":"References","title":"DataFlowTasks.memory_overlap","text":"memory_overlap(di,dj)\n\nDetermine if data di and dj have overlapping memory in the sense that mutating di can change dj (or vice versa). This function is used to build the dependency graph between DataFlowTasks.\n\nA generic version is implemented returning true (but printing a warning). Users should overload this function for the specific data types used in the arguments to allow for appropriate inference of data dependencies.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.memory_overlap-Tuple{Array, Array}","page":"References","title":"DataFlowTasks.memory_overlap","text":"memory_overlap(di::AbstractArray,dj::AbstractArray)\n\nTry to determine if the arrays di and dj have overlapping memory.\n\nWhen both di and dj are Arrays of bitstype, simply compare their addresses. Otherwise, compare their parents by default.\n\nWhen both di and dj are SubArrays we compare the actual indices of the SubArrays when their parents are the same (to avoid too many false positives).\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.nodes-Tuple{DataFlowTasks.DAG}","page":"References","title":"DataFlowTasks.nodes","text":"nodes(dag::DAG)\n\nReturn an iterator over the nodes of dag.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.num_edges-Tuple{DataFlowTasks.DAG}","page":"References","title":"DataFlowTasks.num_edges","text":"num_edges(dag::DAG)\n\nNumber of edges in the DAG.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.num_nodes-Tuple{DataFlowTasks.DAG}","page":"References","title":"DataFlowTasks.num_nodes","text":"num_nodes(dag::DAG)\n\nNumber of nodes in the DAG.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.outneighbors-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.outneighbors","text":"outneighbors(dag,i)\n\nList of successors of j in dag.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.remove_node!-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.remove_node!","text":"remove_node!(dag::DAG,i)\n\nRemove node i and all of its edges from dag.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.savedag","page":"References","title":"DataFlowTasks.savedag","text":"DataFlowTasks.savedag(filepath, graph)\n\nSave graph as an SVG image at filepath. This requires GraphViz to be available.\n\n\n\n\n\n","category":"function"},{"location":"references/#DataFlowTasks.set_active_taskgraph!-Tuple{Any}","page":"References","title":"DataFlowTasks.set_active_taskgraph!","text":"set_active_taskgraph!(tg)\n\nSet the active TaskGraph to tg.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.stack_weakdeps_env!-Tuple{}","page":"References","title":"DataFlowTasks.stack_weakdeps_env!","text":"DataFlowTasks.stack_weakdeps_env!(; verbose = false, update = false)\n\nPush to the load stack an environment providing the weak dependencies of DataFlowTasks. During the development stage, this allows benefiting from the profiling / debugging features of DataFlowTasks without having to install GraphViz or Makie in the project environment.\n\nThis can take quite some time if packages have to be installed or precompiled. Run in verbose mode to see what happens.\n\nAdditionally, set update=true if you want to update the weakdeps environment.\n\nwarning: Warning\nThis feature is experimental and might break in the future.\n\nExamples:\n\nDataFlowTasks.stack_weakdeps_env!()\nusing GraphViz\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.start_dag_cleaner","page":"References","title":"DataFlowTasks.start_dag_cleaner","text":"start_dag_cleaner(tg)\n\nStart a task associated with tg which takes nodes from its finished queue and removes them from the dag. The task blocks if finished is empty.\n\n\n\n\n\n","category":"function"},{"location":"references/#DataFlowTasks.update_edges!-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.update_edges!","text":"update_edges!(dag::DAG,i)\n\nPerform the data-flow analysis to update the edges of node i. Both incoming and outgoing edges are updated.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.with_logging!-Tuple{Any, DataFlowTasks.LogInfo}","page":"References","title":"DataFlowTasks.with_logging!","text":"with_logging!(f,l::LogInfo)\n\nSimilar to with_logging, but append events to l.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.with_logging-Tuple{Any}","page":"References","title":"DataFlowTasks.with_logging","text":"with_logging(f) --> f(),loginfo\n\nExecute f() and log DataFlowTasks into the loginfo object.\n\nExamples:\n\nusing DataFlowTasks\n\nA,B = zeros(2), ones(2);\n\nout,loginfo = DataFlowTasks.with_logging() do\n    @dspawn fill!(@W(A),1)\n    @dspawn fill!(@W(B),1)\n    res = @dspawn sum(@R(A)) + sum(@R(B))\n    fetch(res)\nend\n\n#\n\nout\n\nSee also: LogInfo\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.with_taskgraph-Tuple{Any, Any}","page":"References","title":"DataFlowTasks.with_taskgraph","text":"with_taskgraph(f,tg::TaskGraph)\n\nRun f, but push DataFlowTasks to tg.\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks.@dasync-Tuple{Any, Vararg{Any}}","page":"References","title":"DataFlowTasks.@dasync","text":"@dasync expr [kwargs...]\n\nLike @dspawn, but schedules the task to run on the current thread.\n\nSee also:\n\n@dspawn, @dtask\n\n\n\n\n\n","category":"macro"},{"location":"references/#DataFlowTasks.@dspawn-Tuple{Any, Vararg{Any}}","page":"References","title":"DataFlowTasks.@dspawn","text":"@dspawn expr [kwargs...]\n\nSpawn a Julia Task to execute the code given by expr, and schedule it to run on any available thread.\n\nAnnotate the code in expr with @R, @W and/or @RW to indicate how it accesses data (see examples below). This information is used to automatically infer task dependencies.\n\nAdditionally, the following keyword arguments can be provided:\n\nlabel: provide a label to identify the task. This is useful when logging scheduling information;\npriority: inform the scheduler about the relative priority of the task. This information is not (yet) leveraged by the default scheduler.\n\nExamples:\n\nBelow are 3 equivalent ways to create the same Task, which expresses a Read-Write dependency on C and Read dependencies on A and B\n\nusing LinearAlgebra\nusing DataFlowTasks\nA = ones(5, 5)\nB = ones(5, 5)\nC = zeros(5, 5)\nα, β = (1, 0)\n\n# Option 1: annotate arguments in a function call\n@dspawn mul!(@RW(C), @R(A), @R(B), α, β)\n\n# Option 2: specify data access modes in the code block\n@dspawn begin\n   @RW C\n   @R  A B\n   mul!(C, A, B, α, β)\nend\n\n# Option 3: specify data access modes after the code block\n# (i.e. alongside keyword arguments)\nres = @dspawn mul!(C, A, B, α, β) @RW(C) @R(A,B)\n\nfetch(res) # a 5×5 matrix of 5.0\n\nHere is a more complete example, demonstrating a full computation involving 2 different tasks.\n\nusing DataFlowTasks\n\nA = rand(5)\n\n# create a task with WRITE access mode to A\n# and label \"writer\"\nt1 = @dspawn begin\n    @W A\n    sleep(1)\n    fill!(A,0)\n    println(\"finished writing\")\nend  label=\"writer\"\n\n# create a task with READ access mode to A\nt2 = @dspawn begin\n    @R A\n    println(\"I automatically wait for `t1` to finish\")\n    sum(A)\nend  priority=1\n\nfetch(t2) # 0\n\n# output\n\nfinished writing\nI automatically wait for `t1` to finish\n0.0\n\nNote that in the example above t2 waited for t1 because it read a data field that t1 accessed in a writable manner.\n\n\n\n\n\n","category":"macro"},{"location":"references/#DataFlowTasks.@dtask-Tuple{Any, Vararg{Any}}","page":"References","title":"DataFlowTasks.@dtask","text":"@dtask expr [kwargs...]\n\nCreate a DataFlowTask to execute expr, where data have been tagged to specify how they are accessed. Note that the task is not automatically scheduled for execution.\n\nSee @dspawn for information on how to annotate expr to specify data dependencies, and a list of supported keyword arguments.\n\nSee also: @dspawn, @dasync\n\n\n\n\n\n","category":"macro"},{"location":"references/#DataFlowTasks.@log-Tuple{Any}","page":"References","title":"DataFlowTasks.@log","text":"DataFlowTasks.@log expr --> LogInfo\n\nExecute expr and return a LogInfo instance with the recorded events. The Logger waits for the current taskgraph (see get_active_taskgraph to be empty before starting.\n\nwarning: Warning\nThe returned LogInfo instance may be incomplete if block returns before all DataFlowTasks spawened inside of it are completed. Typically expr should fetch the outcome before returning to properly benchmark the code that it runs (and not merely the tasks that it spawns).\n\nSee also: with_logging, with_logging!\n\n\n\n\n\n","category":"macro"},{"location":"references/#GraphViz.Graph-Tuple{DataFlowTasks.LogInfo}","page":"References","title":"GraphViz.Graph","text":"GraphViz.Graph(log_info::LogInfo)\n\nProduce a GraphViz.Graph representing the DAG of tasks collected in log_info.\n\nSee also: DataFlowTasks.@log\n\n\n\n\n\n","category":"method"},{"location":"references/#DataFlowTasks_GraphViz_Ext.loggertodot-Tuple{Any}","page":"References","title":"DataFlowTasks_GraphViz_Ext.loggertodot","text":"loggertodot(logger)  --> dagstring\n\nReturn a string in the DOT format representing the underlying graph in logger and to be plotted by GraphViz with Graph(loggertodot())\n\n\n\n\n\n","category":"method"},{"location":"references/#MakieCore.plot-Tuple{DataFlowTasks.LogInfo}","page":"References","title":"MakieCore.plot","text":"plot(log_info; categories)\n\nPlot DataFlowTasks log_info labeled informations with categories.\n\nEntries in categories define how to group tasks in categories for plotting. Each entry can be:\n\na String: in this case, all tasks having labels in which the string occurs are grouped together. The string is also used as a label for the category itself.\na String => Regex pair: in this case, all tasks having labels matching the regex are grouped together. The string is used as a label for the category itself.\n\nSee the documentation for more information on how to profile and visualize DataFlowTasks.\n\n\n\n\n\n","category":"method"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"EditURL = \"lcs.jl\"","category":"page"},{"location":"examples/lcs/lcs/#Longest-Common-Subsequence","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"","category":"section"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"(Image: ipynb) (Image: nbviewer)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"The problem of finding the Longest Common Subsequence between two sequences finds numerous applications in fields as diverse as computer sciences or bioinformatics. In this example, we'll implement a parallel dynamic programming approach to solving such problems.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"The idea behind this approach is that, if we denote by LCS(XY) the longest common subsequence of two sequences X and Y, then LCS satisfies the two following properties:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"beginalign\n LCS(X*c Y*c) = LCS(X Y) * c \n LCS(X*c_1 Y*c_2) in left LCS(X*c_1 Y) LCS(X Y*c_2)right  textif  c_1 neq c_2\nendalign","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"where X*c denotes the concatenation of sequence X with character c. The first property above allows simplifying the Longest Common Subsequence computation of two sequences that end with the same character. When the two sequences end with different characters, the second property allows simplifying the problem to a choice between two possibilities.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"If we now denote by L_ij the length of the longest common subsequence between the first i characters of X and the first j characters of Y, then we now have the following property for L:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"L_ij = left\nbeginarrayll\n0  text if  i=0 text or  j=0\n1 + L_i-1 j-1  text if  ineq 0 text and  jneq 0 text and  x_i = y_j\ntextmaxleft(L_i-1 j L_ij-1right)  text if  ineq 0 text and  jneq 0 text and  x_i neq y_j\nendarray\nright","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"where x_i represents the i-th character in sequence X and y_j the j-th character in sequence Y.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"If L is stored in an array, the first condition above allows initializing its first row and first column. Then, the neighboring cells can be filled using the two other conditions, which in turn unlocks further neighboring cells until the whole L matrix is filled.","category":"page"},{"location":"examples/lcs/lcs/#Small-example","page":"Longest Common Subsequence","title":"Small example","text":"","category":"section"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Let us begin with a small example: we want to find a longest common subsequence between GAC and AGCAT:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"x = collect(\"GAC\");\ny = collect(\"AGCAT\");\nnothing #hide","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Let's build the L array. For the sake of the example, we'll initially fill it with (-1) in order to indicate which values haven't been computed yet. The init_buffer(x,y) function simply initiaizes a buffer matrix L of the appropriate size, while init_length!(L) takes a matrix and fills its first row and first column with zeros. We also define a display helper function, which shows a pretty representation of the L array.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"init_buffer(x, y) = Matrix{Int}(undef, 1 + length(x), 1 + length(y))\n\nfunction init_lengths!(L)\n    L[:, 1] .= 0\n    return L[1, :] .= 0\nend\n\nusing PrettyTables\nfunction display(L, x, y)\n    return pretty_table(\n        hcat(['∅', x...], L);\n        header = [' ', '∅', y...],\n        formatters = (v, i, j) -> v == -1 ? \"\" : v,\n    )\nend\n\nL = fill!(init_buffer(x, y), -1)\ninit_lengths!(L)\ndisplay(L, x, y)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"The fill_lengths! function then allows filling other rows. By default it will fill the entire array, but for the sake of the example we restrict it here to a subset of the rows and/or the columns.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"function fill_lengths!(L, x, y, ir = eachindex(x), jr = eachindex(y))\n    @inbounds for j in jr, i in ir\n        L[i+1, j+1] = (x[i] == y[j]) ? L[i, j] + 1 : max(L[i+1, j], L[i, j+1])\n    end\nend\n\nfill_lengths!(L, x, y, 1:1)\ndisplay(L, x, y)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"After the first row has been filled, we see that L_11 = 0 because we can't extract any common subsequence from the first characters in X (G) and Y (A). However, L_12=1 because the first character of X (G) matches the second character of Y (which is also G). In turn this causes all other L_1j values to be equal to 1.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Now that the first row is complete, we can fill the remaining two rows in the array:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"fill_lengths!(L, x, y, 2:3)\ndisplay(L, x, y)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"We now know that the longest common subsequence between X and Y has a length of 2. In order to actually find a subsequence of this length, we can \"backtrack\" from the bottom right of the array back to the top left:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"function backtrack(L, x, y)\n    i = lastindex(x)\n    j = lastindex(y)\n    subseq = Char[]\n    while L[i+1, j+1] != 0\n        if x[i] == y[j]\n            pushfirst!(subseq, x[i])\n            (i, j) = (i - 1, j - 1)\n        elseif L[i+1, j] > L[i, j+1]\n            (i, j) = (i, j - 1)\n        else\n            (i, j) = (i - 1, j)\n        end\n    end\n    return String(subseq)\nend\n\nbacktrack(L, x, y)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Wrapping everything into a function, we get","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"function LCS!(L, x, y)\n    init_lengths!(L)\n    fill_lengths!(L, x, y)\n    return backtrack(L, x, y)\nend\nLCS(x, y) = LCS!(init_buffer(x, y), x, y)\n\nLCS(x, y)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Note that we define both an in-place version of the algorithm, which takes a pre-allocated array as input, and another version which allocates the array internally.","category":"page"},{"location":"examples/lcs/lcs/#Large-example","page":"Longest Common Subsequence","title":"Large example","text":"","category":"section"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Let's test this on larger data. The results obtained with this sequential version of the algorithm will serve as reference to check the validity of more complex implementations.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"import Random;\nRandom.seed!(42);\nx = rand(\"ATCG\", 4096);\ny = rand(\"ATCG\", 8192);\nseq = LCS(x, y)\nlength(seq)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"We can also measure the elapsed time for this implementation, which will serve as a base line to assess the performance of other implementations described below.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"using BenchmarkTools\nBenchmarkTools.DEFAULT_PARAMETERS.seconds = 1\nt_seq = @belapsed LCS!(L, $x, $y) setup = (L = init_buffer(x, y))","category":"page"},{"location":"examples/lcs/lcs/#Tiled-sequential-version","page":"Longest Common Subsequence","title":"Tiled sequential version","text":"","category":"section"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"We'll now build a tiled version of the same algorithm. The TiledIteration.jl package implements various tools allowing to define and iterate over disjoint tiles of a larger array. Among these, the SplitAxis function allows splitting a range of indices into a given number of chunks:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"using TiledIteration\nSplitAxis(1:20, 3)  # split the range 1:20 into 3 chunks of approximately equal sizes","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"A tiled version of the previous algorithm is then as simple as filling the chunks one after the other:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"function LCS_tiled!(L, x, y, nx, ny)\n    init_lengths!(L)\n    for jrange in SplitAxis(eachindex(y), ny)\n        for irange in SplitAxis(eachindex(x), nx)\n            fill_lengths!(L, x, y, irange, jrange)\n        end\n    end\n    return backtrack(L, x, y)\nend\nLCS_tiled(x, y, nx, ny) = LCS_tiled!(init_buffer(x, y), x, y, nx, ny)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Here we split the problem into 10 times 10 blocks, and check that the tiled version gives the same results as the plain implementation above. Even without parallelization, and depending on the characteristics of the system, tiling may already be beneficial in terms of performance because it is more cache-friendly:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"nx = ny = 10\ntiled = LCS_tiled(x, y, nx, ny)\n@assert seq == tiled\n\nt_tiled = @belapsed LCS_tiled!(L, $x, $y, nx, ny) setup = (L = init_buffer(x, y))","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"note: Tiling and cache effects\nThe tiled version of the algorithm above is not exactly equivalent to the sequential version, because the array is visited in a different way when the tiles are used. This can have an impact on the performance, depending on the characteristics of the system and the problem size. In particular, the tiled version may be more cache-friendly, which can lead to better performance even in the absence of parallelization.","category":"page"},{"location":"examples/lcs/lcs/#Tiled-parallel-version","page":"Longest Common Subsequence","title":"Tiled parallel version","text":"","category":"section"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Parallelizing the tiled version using DataFlowTasks is now relatively straightforward: it only requires annotating the code to expose data dependencies.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"In our case:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"the initialization task writes to the first row and first column of the array. In this parallel implementation, initialization will be done tile-by-tile as well using fill! on a view of L;\nfilling a tile involves reading L for the provided ranges of indices, and writing to a range of indices shifted by 1;\nbacktracking reads the whole L array.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Note that the backtracking task needs to be fetched in order to get the result in a synchronous way and perform an apple-to-apple comparison to the previous implementations.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"using DataFlowTasks\n\ninit_lengths!(L, ir, jr) = fill!(view(L, ir, jr), 0)\n\nfunction LCS_par!(L, x, y, nx, ny)\n    L[1,1] = 0\n    for (ky, jrange) in enumerate(SplitAxis(eachindex(y), ny))\n        L1j = view(L, 1, jrange .+ 1)\n        @dspawn fill!(@W(L1j), 0) label = \"init (1, $(ky+1))\"\n        for (kx, irange) in enumerate(SplitAxis(eachindex(x), nx))\n            Lx1 = view(L, irange .+ 1, 1)\n            ky == 1 && @dspawn fill!(@W(Lx1), 0) label = \"init ($(kx+1), 1)\"\n            @dspawn begin\n                @R view(L, irange, jrange)\n                @W view(L, irange .+ 1, jrange .+ 1)\n                fill_lengths!(L, x, y, irange, jrange)\n            end label = \"tile ($kx, $ky)\"\n        end\n    end\n\n    bt = @dspawn backtrack(@R(L), x, y) label = \"backtrack\"\n    return fetch(bt)\nend\nLCS_par(x, y, nx, ny) = LCS_par!(init_buffer(x, y), x, y, nx, ny)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Again, we can check that this implementation produces the correct results, and measure its run-time.","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"par = LCS_par(x, y, nx, ny)\n@assert seq == par\nt_par = @belapsed LCS_par!(L, $x, $y, nx, ny) setup = (L = init_buffer(x, y))","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"As an added safety measure, let's also check that the task dependency graph looks as expected:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"import DataFlowTasks as DFT\nresize!(DFT.get_active_taskgraph(), 300)\nGC.gc()\nlog_info = DFT.@log LCS_par(x, y, nx, ny)\n\nDFT.stack_weakdeps_env!()\nusing GraphViz\ndag = GraphViz.Graph(log_info)","category":"page"},{"location":"examples/lcs/lcs/#Performance-comparison","page":"Longest Common Subsequence","title":"Performance comparison","text":"","category":"section"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"using CairoMakie\nbarplot(\n    1:3,\n    [t_seq, t_tiled, t_par];\n    axis = (; title = \"Run times [s]\", xticks = (1:3, [\"sequential\", \"tiled\", \"parallel\"])),\n)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Comparing the performances of these 3 implementations, the tiled version may, depending on the system, already saves some time due to cache effects. The the parallel version does show some speedup, but not as much as one might expect:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"(; nthreads = Threads.nthreads(), speedup  = t_seq / t_par)","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Let's try and understand why. The run-time data collected above contains useful information","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"DFT.describe(log_info; categories = [\"init\", \"tile\", \"backtrack\"])","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"which we can also visualize in a profiling plot. This gives some insight about the performances of our parallel version:","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"plot(log_info; categories = [\"init\", \"tile\", \"backtrack\"])","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"Here, we see for example that the run time is bounded by the length of the critical path, which means that adding more threads would not help much. One way to try and improve the performance is to expose more parallelism by dividing the problem into smaller chunks. Give it a try and see what you get!","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"","category":"page"},{"location":"examples/lcs/lcs/","page":"Longest Common Subsequence","title":"Longest Common Subsequence","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"EditURL = \"cholesky.jl\"","category":"page"},{"location":"examples/cholesky/cholesky/#tiledcholesky-section","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"","category":"section"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"(Image: ipynb) (Image: nbviewer)","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"We illustrate here the use of DataFlowTasks to parallelize a tiled Cholesky factorization. The implementation shown here is delibarately made as simple and self-contained as possible; a more complex and more efficient implementation can be found in the TiledFactorization package.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The Cholesky factorization algorithm takes a symmetric positive definite matrix A and finds a lower triangular matrix L such that A = LLᵀ. The tiled version of this algorithm decomposes the matrix A into tiles (of even sizes, in this simplified version). At each step of the algorithm, we do a Cholesky factorization on the diagonal tile, use a triangular solve to update all of the tiles at the right of the diagonal tile, and finally update all the tiles of the submatrix with a schur complement.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"If we have a matrix A decomposed in n times n tiles, then the algorithm will have n steps. The i-th step (with i in 1n) performs:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":" 1 cholesky factorization of the (ii) tile,\n (i-1) triangular solves (one for each tile in the i-th row of the upper triangular matrix),\n i(i-1)2 matrix multiplications to update the submatrix.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"These are the basic operations on tiles, which we are going to spawn in separate tasks in the parallel implementation. Accounting for all iterations, this makes a total of mathcalO(n^3) such tasks, decomposed as:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":" mathcalO(n) cholesky factorizations,\n mathcalO(n^2) triangular solves,\n mathcalO(n^3) matrix multiplications.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The following image illustrates the 2nd step of the algorithm:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"(Image: )","category":"page"},{"location":"examples/cholesky/cholesky/#Sequential-implementation","page":"Tiled Cholesky Factorization","title":"Sequential implementation","text":"","category":"section"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"A sequential tiled factorization algorithm can be implemented as:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"using LinearAlgebra\n\ntilerange(ti, ts) = (ti-1)*ts+1:ti*ts\n\nfunction cholesky_tiled!(A, ts)\n    m = size(A, 1); @assert m==size(A, 2)\n    m%ts != 0 && error(\"Tilesize doesn't fit the matrix\")\n    n = m÷ts  # number of tiles in each dimension\n\n    T = [view(A, tilerange(i, ts), tilerange(j, ts)) for i in 1:n, j in 1:n]\n\n    for i in 1:n\n        # Diagonal cholesky serial factorization\n        cholesky!(T[i,i])\n\n        # Left tiles update\n        U = UpperTriangular(T[i,i])\n        for j in i+1:n\n            ldiv!(U', T[i,j])\n        end\n\n        # Submatrix update\n        for j in i+1:n\n            for k in j:n\n                mul!(T[j,k], T[i,j]', T[i,k], -1, 1)\n            end\n        end\n    end\n\n    # Construct the factorized object\n    return Cholesky(A, 'U', zero(LinearAlgebra.BlasInt))\nend","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"Let us build a small test case to check the correctness of the factorization. Here we divide a matrix of size 4096×4096 in 8×8 tiles of size 512×512:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"n  = 4096\nts = 512\nA = rand(n, n)\nA = (A + adjoint(A))/2\nA = A + n*I;\nnothing #hide","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"and the results seem to be correct:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"F = cholesky_tiled!(copy(A), ts)\n\n# Check results\nerr = norm(F.L*F.U-A,Inf)/max(norm(A),norm(F.L*F.U))\n@show err\n@assert err < eps(Float64)","category":"page"},{"location":"examples/cholesky/cholesky/#Parallel-implementation","page":"Tiled Cholesky Factorization","title":"Parallel implementation","text":"","category":"section"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"In order to parallelize the code with DataFlowTasks.jl, function calls acting on tiles are wrapped within @dspawn, along with annotations describing data access modes. We also give meaningful labels to the tasks, which will help debug and profile the code.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"using DataFlowTasks\n\nfunction cholesky_dft!(A, ts)\n    m = size(A, 1); @assert m==size(A, 2)\n    m%ts != 0 && error(\"Tilesize doesn't fit the matrix\")\n    n = m÷ts  # number of tiles in each dimension\n\n    T = [view(A, tilerange(i, ts), tilerange(j, ts)) for i in 1:n, j in 1:n]\n\n    for i in 1:n\n        # Diagonal cholesky serial factorization\n        @dspawn cholesky!(@RW(T[i,i])) label=\"chol ($i,$i)\"\n\n        # Left tiles update\n        U = UpperTriangular(T[i,i])\n        for j in i+1:n\n            @dspawn ldiv!(@R(U)', @RW(T[i,j])) label=\"ldiv ($i,$j)\"\n        end\n\n        # Submatrix update\n        for j in i+1:n\n            for k in j:n\n                @dspawn mul!(@RW(T[j,k]), @R(T[i,j])', @R(T[i,k]), -1, 1) label=\"schur ($j,$k)\"\n            end\n        end\n    end\n\n    # Construct the factorized object\n    r = @dspawn Cholesky(@R(A), 'U', zero(LinearAlgebra.BlasInt)) label=\"result\"\n    return fetch(r)\nend","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"Again, let us check the correctness of the result:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"F = cholesky_dft!(copy(A), ts)\n\n# Check results\nerr = norm(F.L*F.U-A,Inf)/max(norm(A),norm(F.L*F.U))\n@show err\n@assert err < eps(Float64)","category":"page"},{"location":"examples/cholesky/cholesky/#Debugging-and-Profiling","page":"Tiled Cholesky Factorization","title":"Debugging and Profiling","text":"","category":"section"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"Let us now check what happens during a parallel run of our cholesky factorization. Thanks to the test above, the code is now compiled. Let's re-run it and collect meaningful profiling information:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"# Clean profiling environment\nGC.gc()\n\n# Real workload to be analysed\nAc = copy(A)\nlog_info = DataFlowTasks.@log cholesky_dft!(Ac, ts)","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The number of tasks being mathcalO(n^3), we can see how quickly the DAG complexity increases (even though the test case only has 8×8 tiles here):","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"DataFlowTasks.stack_weakdeps_env!()\nusing GraphViz\ndag = GraphViz.Graph(log_info)","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The critical path, highlighted in red, includes all cholesky factorizations of diagonal tiles, as well as the required tasks in between them.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"We can also readily get more details about the performance limiting factors:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"DataFlowTasks.describe(log_info; categories=[\"chol\", \"ldiv\", \"schur\"])","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"and, at the price of loading Makie, display these in a more convenient profile plot:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"using CairoMakie # or GLMakie in order to have more interactivity\ntrace = plot(log_info; categories=[\"chol\", \"ldiv\", \"schur\"])","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The overhead incurred by DataFlowTasks seems relatively small here: the time taken inserting tasks is barely measurable, and the scheduling did not lead to threads waiting idly for too long. This is confirmed by the bottom middle plot, showing a measured wall clock time not too much longer than the lower bound obtained when suppressing idle time.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The \"Computing time: breakdown by category\" plot seems to indicate that the matrix multiplications performed in the \"Schur\" tasks account for the majority of the computing time. Trying to optimize these would be a priority to increase the sequential performance of the factorization.","category":"page"},{"location":"examples/cholesky/cholesky/#Performances","page":"Tiled Cholesky Factorization","title":"Performances","text":"","category":"section"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The performance of this example can be improved by using better implementations for the sequential building blocks operating on tiles:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"LoopVectorization.jl can improve the performance of the sequential cholesky factorization of diagonal blocks as well as the schur_complement\nTriangularSolve.jl provides a high-performance ldiv! implementation","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"This approach is pursued in TiledFactorization.jl, where all the above mentioned building blocks are combined with the parallelization strategy presented here to create a pure Julia implementation of the matrix factorizations. The performances of this implementation is assessed in the following plot, by comparison to MKL on a the case of a 5000x5000 matrix decomposed in tiles of size 256x256.","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"(Image: )","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"The figure above was generated by running this script on a machine with 2x10 Intel Xeon Silver 4114 cores (2.20GHz) with the following topology:","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"(Image: )","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"","category":"page"},{"location":"examples/cholesky/cholesky/","page":"Tiled Cholesky Factorization","title":"Tiled Cholesky Factorization","text":"This page was generated using Literate.jl.","category":"page"},{"location":"troubleshooting/#Troubleshooting-/-known-issues","page":"Troubleshooting","title":"Troubleshooting / known issues","text":"","category":"section"},{"location":"troubleshooting/#troubleshooting-captures","page":"Troubleshooting","title":"Tricky behavior of captured variables","text":"","category":"section"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"It is easy to forget that DataFlowTasks.@dspawn, like its siblings @async or Threads.@spawn, wraps its body in an anonymous function. This can lead to unexpected behavior when variables are captured in these closures at task spawn time, and re-bound before task execution time.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"Let's illustrate this with a simple example using plain asynchronous tasks. In the following snippet, the intention is to start with an initial array, double all elements and copy them to a temporary buffer, then double them again and copy them back to the original array:","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"arr = ones(3)\nbuf = fill(NaN, length(arr))\n\n# The following is performed at \"task spawn time\"\nbegin\n    # Warning: these variable bindings will be captured in the task body\n    (from, to) = (arr, buf)\n    task1 = @task to .= 2 .* from\n    \n    # Swap source & destination arrays:\n    # Warning: this re-binds the captures in t1\n    (from, to) = (to, from)\n    task2 = @task begin\n        wait(task1) # make sure the data has been copied before copying it back\n        to .= 2 .* from\n    end\nend\n\n# This is \"task run time\"\nforeach(schedule, (task1, task2))\nwait(task2)\n\narr  # expected all 4 after the round-trip","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"There is however a subtle issue in the code above: the body of task1 captures bindings from and to (not their values at task spawn time). Therefore, when from and to are later re-bound, this affects the captures in task1. If task1 starts afterwards (which we ensure here by only scheduling it later), it \"sees\" the swapped version of from and to, and therefore copies NaNs into the original array.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"note: Note\nIn a real code, one would probably schedule the task as soon as it is created (using @async, Threads.@spawn or DataFlowTasks.@dspawn). In such cases, the result may vary from run to run, depending on whether the task actually starts before the bindings are swapped, or not.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"The fix for such problems usually involves using let-blocks to ensure that task bodies only capture local variables (or at least no variable that is susceptible to be rebound later). For example, the following implementation is safe:","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"arr = ones(3)\nbuf = fill(NaN, length(arr))\n\n# The following is performed at \"task spawn time\"\nbegin\n    (from, to) = (arr, buf)\n    \n    # Thanks to the let-block, the task body captures local bindings\n    task1 = let (src, dest) = (from, to)\n        @task dest .= 2 .* src\n    end\n\n    # Swap source & destination arrays\n    # This rebinds `from` and `to`, but does not affect the captures in task1\n    (from, to) = (to, from)\n    task2 = let (src, dest) = (from, to)\n        @task begin\n            wait(task1)\n            dest .= 2 .* src\n        end\n    end\nend\n\n# This is \"task run time\"\nforeach(schedule, (task1, task2))\nwait(task2)\n\narr  # expect all 4 after the round-trip","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"note: Note\nThe Parallel Merge Sort example shows a real-world situation in which such issues could arise.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"EditURL = \"sort.jl\"","category":"page"},{"location":"examples/sort/sort/#example-sort","page":"Merge sort","title":"Merge sort","text":"","category":"section"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"(Image: ipynb) (Image: nbviewer)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"This example illustrates the use of DataFlowTasks to implement a parallel merge sort algorithm.","category":"page"},{"location":"examples/sort/sort/#Sequential-version","page":"Merge sort","title":"Sequential version","text":"","category":"section"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"We'll use a \"bottom-up\" implementation of the merge sort algorithm. To explain how it works, let's consider a small vector of 32 elements:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"using Random, CairoMakie\ninclude(\"helper.jl\") # plotting utilities\nRandom.seed!(42)\n\nv = randperm(32)\nbarplot(v)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"We decompose it into 4 blocks of 8 elements, which we sort individually:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"sort!(view(v, 1:8))\nsort!(view(v, 9:16))\nsort!(view(v, 17:24))\nsort!(view(v, 25:32))\nbarplot(v; color=ceil.(Int, eachindex(v)./8), colormap=:Paired_4, colorrange=(1,4))","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Now we can merge the first two 8-element blocks into a sorted 16-element block. And do the same for the 3rd and 4th 8-element blocks. We'll need an auxilliary array w to store the results:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"function merge!(dest, left, right)\n    # pre-condition:\n    #   `left`  is sorted\n    #   `right` is sorted\n    #   length(left) + length(right) == length(dest)\n    # post-condition:\n    #   `dest` contains all elements from `left` and `right`\n    #   `dest` is sorted\n\n    (i, j) = (1, 1)\n    (I, J) = (length(left), length(right))\n    @assert I + J == length(dest)\n    @inbounds for k in eachindex(dest)\n        if i <= I && (j > J || left[i] < right[j])\n            dest[k] = left[i]; i += 1\n        else\n            dest[k] = right[j]; j+=1\n        end\n    end\nend\n\nw = similar(v)\n@views merge!(w[1:16],  v[1:8],   v[9:16])\n@views merge!(w[17:32], v[17:24], v[25:32])\nbarplot(w; color=ceil.(Int, eachindex(v)./16), colormap=:Paired_4, colorrange=(1,4))","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Now w is sorted in two blocks, which we can merge to get the entire sorted array. Instead of using a new buffer to store the results, let's re-use the original array v:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"@views merge!(v, w[1:16], w[17:32])\nbarplot(v)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The following sequential implementation automates these steps.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"First, the vector is decomposed in blocks of size bs (64 by default). Each block is sorted using an insertion sort (which works in-place without allocating anything, and is relatively fast for small vectors).","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Then, sorted blocks are grouped in pairs which are merged into the buffer. If the number of blocks is odd, the last block is copied directly to the destination buffer.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The auxiliary buffer is now composed of sorted blocks twice as large as the original blocks, so we can iterate the algorithm with a doubled block size, this time putting the results back to the original vector.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Depending on the parity of the number of iterations, the final result ends up being stored either in the original vector (which is what we want) or in the auxiliary buffer (in which case we copy it back to the original vector). The semantics of mergesort! is thus that of an in-place sort: after the call, v should be sorted.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"function mergesort!(v, buf=similar(v), bs=64)\n    N = length(v)\n\n    for i₀ in 1:bs:N\n        i₁ = min(i₀+bs-1, N)\n        sort!(view(v, i₀:i₁), alg=InsertionSort)\n    end\n\n    (from, to) = (v, buf)\n\n    while bs < length(v)\n        i₀ = 1\n        while i₀ < N\n            i₁ = i₀+bs; i₁>N && break\n            i₂ = min(i₀+2bs-1, N)\n            @views merge!(to[i₀:i₂], from[i₀:i₁-1], from[i₁:i₂])\n\n            i₀ = i₂+1\n        end\n        if i₀ <= N\n            @inbounds @views to[i₀:N] .= from[i₀:N]\n        end\n\n        bs *= 2\n        (from, to) = (to, from)\n    end\n\n    v === from || copy!(v, from)\n    v\nend\n\nN = 100_000\nv = rand(N)\nbuf = similar(v)\n\n@assert issorted(mergesort!(copy(v), buf))","category":"page"},{"location":"examples/sort/sort/#Parallel-version","page":"Merge sort","title":"Parallel version","text":"","category":"section"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Parallelizing with DataFlowTasks involves splitting the work into several parallel tasks, which have to be annotated to list their data dependencies. In our case:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Sorting each initial block involves calling the sequential implementation on it. The block size is larger here, to avoid spawning tasks for too small chunks. Each such task modifies its own block in-place.\nMerging two blocks (or copying a lone block) reads part of the source array, and writes to (the same) part of the destination array.\nA final task reads the whole array to act as a barrier: we can fetch it to synchronize all other tasks and get the result.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"using DataFlowTasks\n\nfunction mergesort_dft!(v, buf=similar(v), bs=16384)\n    N = length(v)\n\n    for i₀ in 1:bs:N\n        i₁ = min(i₀+bs-1, N)\n        @dspawn mergesort!(@RW(view(v, i₀:i₁))) label=\"sort\\n$i₀:$i₁\"\n    end\n\n    # WARNING: (from, to) are not local to each task but will later be re-bound\n    # => avoid capturing them\n    (from, to) = (v, buf)\n\n    while bs < N\n        i₀ = 1  # WARNING: i₀ is not local to each task; avoid capturing it\n        while i₀ < N\n            i₁ = i₀+bs; i₁>N && break\n            i₂ = min(i₀+2bs-1, N)\n            let # Create new bindings which will be captured in the task body\n                left  = @view from[i₀:i₁-1]\n                right = @view from[i₁:i₂]\n                dest  = @view to[i₀:i₂]\n                @dspawn merge!(@W(dest), @R(left), @R(right)) label=\"merge\\n$i₀:$i₂\"\n            end\n            i₀ = i₂+1\n        end\n        if i₀ <= N\n            let # Create new bindings which will be captured in the task body\n                src  = @view from[i₀:N]\n                dest = @view to[i₀:N]\n                @dspawn @W(dest) .= @R(src) label=\"copy\\n$i₀:$N\"\n            end\n        end\n\n        bs *= 2\n        (from, to) = (to, from)\n    end\n\n    final_task = @dspawn @R(from) label=\"result\"\n    fetch(final_task)\n    v === from || copy!(v, from)\n    v\nend\n\n@assert issorted(mergesort_dft!(copy(v), buf))","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"note: Captured bindings\nThe swapping of variables from and to could cause hard-to-debug issues if these bindings were captured into the task bodies. The same is true of variable i₀, which is repeatedly re-bound in the while-loop (as opposed to what classically happens with a for loop, which creates a new binding at each iteration).This is a real-world occurrence of the situation described in more details in the troubleshooting page.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"As expected, the task graph looks like a (mostly binary) tree:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"log_info = DataFlowTasks.@log mergesort_dft!(copy(v))\n\nusing GraphViz\ndag = GraphViz.Graph(log_info)","category":"page"},{"location":"examples/sort/sort/#Performance","page":"Merge sort","title":"Performance","text":"","category":"section"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Let's use bigger data to assess the performance of our implementations:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"N = 1_000_000\ndata = rand(N);\nbuf  = similar(data);\n\nusing BenchmarkTools\nbench_seq = @benchmark mergesort!(x, $buf) setup=(x=copy(data)) evals=1","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"bench_dft = @benchmark mergesort_dft!(x, $buf) setup=(x=copy(data)) evals=1","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The parallel version does exhibit some speed-up, but not as much as one would hope for given the number of threads used in the computation:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"(;\n nthreads = Threads.nthreads(),\n speedup = time(minimum(bench_seq)) / time(minimum(bench_dft)))","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"To better understand why the speedup may not be as good as expected, we can inspect the execution trace of the parallel version and visualize it using Makie:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"log_info = DataFlowTasks.@log mergesort_dft!(copy(data))\nplot(log_info; categories = [\"sort\", \"merge\", \"copy\", \"result\"])","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The parallel profile explains it all: at the beginning of the computation, sorting the small blocks and merging them involves a large number of small tasks. There is a lot of expressed parallelism to be taken advantage of at this stage, and DataFlowTasks seems to do a good job. But as the algorithm advances, fewer and fewer blocks have to be merged, which are larger and larger... until the last merge of the whole array (which is performed sequentially) seemingly accounts for as much as 25% of the whole computation time!","category":"page"},{"location":"examples/sort/sort/#Parallel-merge","page":"Merge sort","title":"Parallel merge","text":"","category":"section"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"In order to express more parallelism in the algorithm, it is therefore important to perform large merges in parallel. There exist many elaborate parallel binary merge algorithms; here we describe a relatively naive one:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"# Assuming we want to sort `v`, and its `left` and `right` halves have already\n# been sorted, we merge them into `dest`:\nv = randperm(64)\nleft  = @views v[1:32]; sort!(left)\nright = @views v[33:64]; sort!(right)\ndest = similar(v)\n\n(I, J, K) = length(left), length(right), length(dest)\n@assert I+J == K\n\n# First we find a pivot value, which splits `left` in two halves:\ni = 1 + I ÷ 2\npivot = left[i-1]\n\n# Next we split `right` into two parts: indices associated to values lower than\n# the pivot, and indices associated to values larger than the pivot. Since the\n# data is sorted, an efficient binary search algorithm can be used:\nj = searchsortedfirst(right, pivot)\n\n# We now have both `left` and `right` decomposed into two (hopefully nearly\n# equal) parts:\n(i₁, i₂) = (1:i-1, i:I)  # partition of `left`\n(j₁, j₂) = (1:j-1, j:J)  # partition of `right`\n\ndisplay_split(v, i₁, i₂, j₁, j₂)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Between them, the first part of left and the first part of right contain all values lower than or equal to pivot: they can be merged together in the first part of the destination array, which will also contain all values lower than or equal to pivot.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The same is true of the second parts of left and right, which contain all values larger than pivot and can be merged into the second part of the destination array.","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"# Find the index which splits `dest` into two parts, according to the number of\n# elements in the first parts of `left` and `right`\nk = i + j - 1\n(k₁, k₂) = (1:k-1, k:K)  # partition of `dest`\n\n# Merge the first parts\n@views merge!(dest[k₁], left[i₁], right[j₁])\n\n# Merge the second parts\n@views merge!(dest[k₂], left[i₂], right[j₂])\n\n# We now have a fully sorted array\n@assert issorted(dest)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The following function automates the splitting of the arrays into P parts, desribed as a vector of (iₚ, jₚ, kₚ) tuples:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"function split_indices(P, dest, left, right)\n    (I, J, K) = length(left), length(right), length(dest)\n    @assert I+J == K\n\n    i = ones(Int, P+1)\n    j = ones(Int, P+1)\n    k = ones(Int, P+1)\n    for p in 2:P\n        i[p] = 1 + ((p-1)*I) ÷ P\n        j[p] = searchsortedfirst(right, left[i[p]-1])\n        k[p] = k[p-1] + i[p]-i[p-1] + j[p]-j[p-1]\n    end\n    i[P+1] = I+1; j[P+1] = J+1; k[P+1] = K+1\n\n    map(1:P) do p\n        (i[p]:i[p+1]-1, j[p]:j[p+1]-1, k[p]:k[p+1]-1)\n    end\nend\n\n# Check that this decomposes `left` and `right` into the same ranges as shown\n# in the figure above:\nsplit_indices(2, dest, left, right)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"This can serve as a building block for a parallel merge and new version of the parallel merge sort:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"function parallel_merge_dft!(dest, left, right; label=\"\")\n    # Number of parts in which large blocks will be split\n    P = min(8, ceil(Int, length(dest)/65_536))\n\n    # Simple sequential merge for small cases\n    if P <= 1\n        @dspawn merge!(@W(dest), @R(left), @R(right)) label=\"merge\\n$label\"\n        return dest\n    end\n\n    # Split the arrays into `P` parts. It is important to use `@dspawn` here so\n    # that `split_indices` wait until the previous tasks are finished sorting\n    idxs_t = @dspawn split_indices(P, @R(dest), @R(left), @R(right)) label=\"split\\n$label\"\n    idxs   = fetch(idxs_t)::Vector{NTuple{3, UnitRange{Int}}}\n\n    # Spawn one task per part\n    for p in 1:P\n        part = 'A' + p -1\n        iₚ, jₚ, kₚ = idxs[p]\n        left′, right′, dest′ = @views left[iₚ], right[jₚ], dest[kₚ]\n        @dspawn merge!(@W(dest′), @R(left′), @R(right′)) label=\"merge $part\\n$label\"\n    end\n    return dest\nend","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"With this parallel merge version, we can now re-write the mergesort algorithm to spawn parallel merge tasks:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"function parallel_mergesort_dft!(v, buf=similar(v); bs=16384)\n    N = length(v)\n\n    for i₀ in 1:bs:N\n        i₁ = min(i₀+bs-1, N)\n        @dspawn mergesort!(@RW(view(v, i₀:i₁))) label=\"sort\\n$i₀:$i₁\"\n    end\n\n    (from, to) = (v, buf)\n\n    while bs < N\n        i₀ = 1\n        while i₀ < N\n            i₁ = i₀+bs; i₁>N && break\n            i₂ = min(i₀+2bs-1, N)\n            let\n                left  = @view from[i₀:i₁-1]\n                right = @view from[i₁:i₂]\n                dest  = @view to[i₀:i₂]\n                parallel_merge_dft!(dest, left, right, label=\"$i₀:$i₂\")\n            end\n            i₀ = i₂+1\n        end\n        if i₀ <= N\n            let\n                src  = @view from[i₀:N]\n                dest = @view to[i₀:N]\n                @dspawn @W(dest) .= @R(src) label=\"copy\\n$i₀:$N\"\n            end\n        end\n\n        bs *= 2\n        (from, to) = (to, from)\n    end\n\n    final_task = @dspawn @R(from) label=\"result\"\n    fetch(final_task)\n    v === from || copy!(v, from)\n    v\nend","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Let us check that this new version still works as expected:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"N = 100_000\nv = rand(N)\n@assert issorted(parallel_mergesort_dft!(copy(v)))","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The task graph is now a bit more complicated. Here we see for example that the last level of merge has been split into 2 parts (labelled \"merge A\" and \"merge B\"):","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"# Temporarily stop the DAG cleaner from dynamically removing nodes from the task\n# graph in order to obtain the full \"static graph\".\nDataFlowTasks.stop_dag_cleaner()\nlog_info = DataFlowTasks.@log parallel_mergesort_dft!(copy(v))\nDataFlowTasks.start_dag_cleaner()\n\nusing GraphViz\ndag = GraphViz.Graph(log_info)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Since it expresses more parallelism, this new version performs better:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"buf = similar(data)\nbench_dft_tiled = @benchmark parallel_mergesort_dft!(x, $buf) setup = (x = copy(data)) evals = 1","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"(;\n    nthreads = Threads.nthreads(),\n    speedup = time(minimum(bench_seq)) / time(minimum(bench_dft_tiled)),\n)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"The profile plot also shows how merge tasks remain parallel until the very end:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"log_info = DataFlowTasks.@log parallel_mergesort_dft!(copy(data))\nplot(log_info, categories=[\"sort\", \"merge\", \"copy\", \"result\", \"split\"])","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"Here, one extra performance limiting factor is the additional work performed by the parallel merge algorithm (e.g. finding pivots). Compare for example the sequential elapsed time:","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"bench_seq","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"to the cumulated run time of the tasks (shown as \"Computing\" in the log_info description):","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"DataFlowTasks.describe(log_info)","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"","category":"page"},{"location":"examples/sort/sort/","page":"Merge sort","title":"Merge sort","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"EditURL = \"blur-roberts.jl\"","category":"page"},{"location":"examples/blur-roberts/blur-roberts/#Blur-and-Roberts-image-filters","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"","category":"section"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"(Image: ipynb) (Image: nbviewer)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"This example illustrate the use of DataFlowTasks.jl to parallelize the tiled application of two kernels used in image processing. The application first applies a blur filter on each pixel of the image; in a second step, the Roberts cross operator is applied to detect edges in the image.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Let us first load a test image:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"using Images\nurl = \"https://upload.wikimedia.org/wikipedia/commons/c/c3/Equus_zebra_hartmannae_-_Etosha_2015.jpg\"\nispath(\"test-image.jpg\") || download(url, \"test-image.jpg\")\nimg = Gray.(load(\"test-image.jpg\"))","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"We start by defining a few helper functions:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"the contract and expand functions manipulate ranges of indices in order to respectively contract or expand them by a few pixels;\nthe img2mat and mat2img convert between a Gray-scale image and a matrix of floating-point pixel intensities. The filters will work on this latter representation, which may need a renormalization to be converted back to a Gray-scale image.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"contract(range,n) = range[begin+n:end-n]\nexpand(range,n)   = range[begin]-n:range[end]-n\n\nfunction img2mat(img)\n    PixelType = eltype(img)\n    mat = Float64.(img)\n    return (PixelType, mat)\nend\n\nfunction mat2img(PixelType, mat)\n    m1, m2 = extrema(mat)\n    PixelType.((mat .- m1) ./ (m2-m1))\nend\n\nPixelType, mat = img2mat(img);\nnothing #hide","category":"page"},{"location":"examples/blur-roberts/blur-roberts/#Filters-implementation","page":"Blur & Roberts image filters","title":"Filters implementation","text":"","category":"section"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"The blur! function averages the value of each pixel with the values of all pixels less than width pixels away in manhattan distance. In order to simplify the implementation, the filter is applied only to pixels that are sufficiently far from the boundary to have all their neighbors correctly defined.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Results are written in-place in a pre-allocated dest array. Unless otherwise specified, the filter is applied to the whole image, but can be reduced to a tile if a smaller range argument is provided.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"function blur!(dest, src; range=axes(src), width)\n    ri, rj = intersect.(range, contract.(axes(src), width))\n\n    weight = 1/(2*width+1)^2\n    @inbounds for i in ri, j in rj\n        dest[i,j] = 0\n        for δi in -width:width, δj in -width:width\n            dest[i,j] += src[i+δi, j+δj]\n        end\n        dest[i,j] *= weight\n    end\nend","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"In the following, we'll use a filter width of 5 pixels, which produces the following results on the test image:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"width = 5\nblurred = zero(mat)\n\nblur!(blurred, mat; width)\n\nmat2img(PixelType, blurred)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"The roberts! function applies the Roberts cross operator to the provided  image. Like above, it operates by default on all pixels in the image  (provided they are sufficiently far from the boundaries), but can be  restricted to work on a tile if the range argument is provided.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"function roberts!(dest, src; range=axes(src))\n    ri, rj = intersect.(range, contract.(axes(src), 1))\n\n    for i in ri, j in rj\n        dest[i,j] = (\n            + (sqrt(src[i,  j]) - sqrt(src[i+1,j+1]))^2\n            + (sqrt(src[i+1,j]) - sqrt(src[i  ,j+1]))^2\n        )^(0.25)\n    end\nend","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Applying this edge detection filter on the original image produces the following results:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"contour = zero(mat)\nroberts!(contour, mat)\n\nmat2img(PixelType, contour)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Chaining the blur and roberts filters may make edge detection less noisy:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"function blur_roberts!(img; width, tmp=zero(img))\n    blur!(tmp, img; width)\n    roberts!(img, tmp)\nend\n\nmat1 = copy(mat)\ntmp  = zero(mat)\n\nblur_roberts!(mat1; width, tmp)\nmat2img(PixelType, mat1)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"The elapsed time in this sequential version will serve as reference to evaluate the performance of other implementations:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"using BenchmarkTools\nt_seq = @belapsed blur_roberts!(x, width=$width, tmp=$tmp) setup=(x=copy(mat)) evals=1","category":"page"},{"location":"examples/blur-roberts/blur-roberts/#Tiled-filter-application","page":"Blur & Roberts image filters","title":"Tiled filter application","text":"","category":"section"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"The TiledIteration.jl package implements various tools allowing to define and iterate over disjoint tiles of a larger array. We'll use it to apply the filters tile by tile.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"The map_tiled! higher-order function automates the application of a filter fun! on all pixels of an image src decomposed with a tilesize ts. This higher-order function is then used to define tiled versions of the blur and roberts filters.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"using TiledIteration\n\nfunction map_tiled!(fun!, dest, src, ts)\n    for tile in TileIterator(axes(src), (ts, ts))\n        fun!(dest, src, tile)\n    end\nend\n\nblur_tiled!(dest, src, ts; width) = map_tiled!(dest, src, ts) do dest, src, tile\n    blur!(dest, src; width, range=tile)\nend\n\nroberts_tiled!(dest, src, ts) = map_tiled!(dest, src, ts) do dest, src, tile\n    roberts!(dest, src; range=tile)\nend\n\nfunction blur_roberts_tiled!(img, ts; width, tmp=zero(img))\n    blur_tiled!(tmp, img, ts; width)\n    roberts_tiled!(img, tmp, ts)\nend","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Decomposing the original image in tiles of size 512times 512, the tiled application of the filters yields the same result as above:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"ts = 512\n\nmat1 .= mat\nblur_roberts_tiled!(mat1, ts; width, tmp)\n\nmat2img(PixelType, mat1)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Depending on the system, the fact that memory is now accessed in blocks may (or may not) have a significant impact on the performance, due to cache effects.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"t_tiled = @belapsed blur_roberts_tiled!(x, ts; width=$width, tmp=$tmp) setup=(x=copy(mat)) evals=1","category":"page"},{"location":"examples/blur-roberts/blur-roberts/#Parallel-filter-application","page":"Blur & Roberts image filters","title":"Parallel filter application","text":"","category":"section"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Parallelizing the tiled filter application is relatively straightforward using DataFlowTasks.jl. As usual, it involves specifying which data is accessed by each task.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"using DataFlowTasks\n\nfunction blur_dft!(dest, src, ts; width)\n    map_tiled!(dest, src, ts) do dest, src, tile\n        outer = intersect.(expand.(tile, width), axes(src))\n        @dspawn begin\n            @R view(src, outer...)\n            @W view(dest, tile...)\n            blur!(dest, src; width, range=tile)\n        end label=\"blur ($tile)\"\n    end\n    @dspawn @R(dest) label=\"blur (result)\"\nend\n\nfunction roberts_dft!(dest, src, ts)\n    map_tiled!(dest, src, ts) do dest, src, tile\n        outer = intersect.(expand.(tile, 1), axes(src))\n        @dspawn begin\n            @R view(src, outer...)\n            @W view(dest, tile...)\n            roberts!(dest, src; range=tile)\n        end label=\"roberts ($tile)\"\n    end\n    @dspawn @R(dest) label=\"roberts (result)\"\nend","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Note how each filter spawns one task for each tile, and an extra task to get the results in the end. This allows applying a given filter independently of the other.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"However, the filters remain composable: when applying both filters one after the other, no implicit synchronization is enforced at the end of the blurring stage, and the runtime may decide to intersperse blurring and roberts tasks (as long as the blurring of a tile and all its neighbors is performed before the application of the roberts filter on this tile).","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"function blur_roberts_dft!(img, ts; width, tmp=zero(img))\n    blur_dft!(tmp, img, ts; width)\n    roberts_dft!(img, tmp, ts)\n    @dspawn @R(img) label=\"result\"\nend","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"Again this yields the same results on the test image:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"mat1 .= mat;\nblur_roberts_dft!(mat1, ts; width, tmp) |> wait\n\nmat2img(PixelType, mat1)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"t_dft = @belapsed wait(blur_roberts_dft!(x, ts; width=$width, tmp=$tmp)) setup=(x = copy(mat)) evals=1","category":"page"},{"location":"examples/blur-roberts/blur-roberts/#Performance-analysis","page":"Blur & Roberts image filters","title":"Performance analysis","text":"","category":"section"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"DataFlowTasks.stack_weakdeps_env!()\nusing CairoMakie\n\nbarplot([t_seq, t_tiled, t_dft],\n        axis = (; title = \"Elapsed time [s]\",\n                xticks=(1:3, [\"sequential\", \"tiled\", \"DataFlowTasks\"])))","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"A comparison of the performances of all implementations shows that the DataFlowTasks-based implementation produces a good speedup:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"(;\n nthreads = Threads.nthreads(),\n speedup = t_seq / t_dft)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"We can gain more insight by collecting profiling data:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"GC.gc()\nmat1 .= mat;\nlog_info = DataFlowTasks.@log wait(blur_roberts_dft!(mat1, ts; width, tmp))\nDataFlowTasks.describe(log_info)","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"The parallel trace shows how blur and roberts tasks are interspersed in the time line:","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"trace = plot(log_info, categories=[\"blur\", \"roberts\"])","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"In terms of performance, elapsed time seems to be bounded in this case by the total computing time of all threads. Re-running the same computation with more threads may help reduce the overall wall-clock time.","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"","category":"page"},{"location":"examples/blur-roberts/blur-roberts/","page":"Blur & Roberts image filters","title":"Blur & Roberts image filters","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"CurrentModule = DataFlowTasks","category":"page"},{"location":"#DataFlowTasks","page":"Getting started","title":"DataFlowTasks","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Tasks which automatically respect data-flow dependencies","category":"page"},{"location":"#Basic-usage","page":"Getting started","title":"Basic usage","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"This package defines a @dspawn macro type which behaves very much like Threads.@spawn, except that it allows the user to specify explicit data dependencies for the spawned Task. This information is then be used to automatically infer task dependencies by constructing and analyzing a directed acyclic graph based on how tasks access the underlying data. The premise is that it is sometimes simpler to specify how tasks depend on data than to specify how tasks depend on each other.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"When creating a Task using @dspawn, the following annotations can be used to declare how the Task accesses the data:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"read-only: @R or @READ\nwrite-only: @W or @WRITE\nread-write: @RW or @READWRITE","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"An @R(A) annotation for example implies that data A will be accessed in read-only mode by the task. Here is a simple example:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using DataFlowTasks\n\nn = 100_000\nA = ones(n)\n\nd1 = @dspawn begin\n    @RW A\n\n    # in-place work on A\n    for i in eachindex(A)\n        A[i] = log(A[i]) # A[i] = 0\n    end\nend\n\n# reduce A\nd2 = @dspawn sum(@R A)\n# The above is a shortcut for:\n#   d2 = @dspawn begin\n#       @R A\n#       sum(A)\n#   end\n\nc = fetch(d2) # 0","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Two (asynchronous) tasks were created, both of which access the array A. Because d1 writes to A, and d2 reads from it, the outcome C is nondeterministic unless we specify an order of precedence. DataFlowTasks reinforces the sequential consistency criterion, which is to say that executing tasks in parallel must preserve, up to rounding errors, the result that would have been obtained if they were executed sequentially, following the order in which they were created. In the example above, this means d2 will wait on d1 because of an inferred data dependency. The outcome is thus always zero.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"note: Note\nIf you replace DataFlowTasks.@dspawn by Threads.@spawn in the example above (and pick an n large enough) you will see that you no longer get 0 because d2 may access an element of A before it has been replaced by zero!","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"tip: Tip\nIn the d2 example above, a shortcut syntax was introduced, which allows putting access mode annotations directly around arguments in a function call. This is especially useful when the task body is a one-liner. See @dspawn for an exhaustive list of supported ways to create tasks and specify data dependencies.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"No parallelism was allowed in the previous example due to a data conflict. To see that when parallelism is possible, DataFlowTasks will exploit it, consider this one last example:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using DataFlowTasks\n\nfunction run(A)\n    d1 = @dspawn begin\n        @W A # write to A\n        sleep(1)\n        fill!(A,0)\n    end\n\n    # a reduction on A\n    d2 = @dspawn begin\n        @R A # read from A\n        sleep(10)\n        sum(A)\n    end\n\n    # another reduction on A\n    d3 = @dspawn sum(@R(A))\n\n    t = @elapsed c = fetch(d3)\n\n    @show t,c\nend\n\nA = ones(10)\nrun(A)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"We see that the elapsed time to fetch the result from d3 is on the order of one second. This is expected since d3 needs to wait on d1 but can be executed concurrently with d2. The result is, as expected, 0.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"All examples this far have been simple enough that the dependencies between the tasks could (and probably should) have been inserted by hand. There are certain problems, however, where the constant reuse of memory (mostly for performance reasons) makes a data-flow approach to parallelism a rather natural way to implicitly describe task dependencies. This is the case, for instance, of tiled (also called blocked) matrix factorization algorithms, where task dependencies can become rather difficult to describe in an explicit manner. The tiled factorization section showcases some non-trivial problems for which DataFlowTasks may be useful.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"tip: Tip\nThe main goal of DataFlowTasks is to expose parallelism: two tasks ti and tj can be executed concurrently if one does not write to memory that the other reads. This data-dependency check is done dynamically, and therefore is not limited to tasks in the same lexical scope. Of course, there is an overhead associated with these checks, so whether performance gains can be obtained depend largely on how parallel the algorithm is, as well as how long each individual task takes (compared to the overhead).","category":"page"},{"location":"#Custom-types","page":"Getting started","title":"Custom types","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"In order to infer dependencies between DataFlowTasks, we must be able to determine whether two objects A and B share a common memory space. That is to say, we must know if mutating A can affect B, or vice-versa. This check is performed by the memory_overlap function:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using DataFlowTasks: memory_overlap\n\nA = rand(10,10)\nB = view(A,1:10)\nC = view(A,11:20)\n\nmemory_overlap(A,B), memory_overlap(A,C), memory_overlap(B,C)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The example above works because memory_overlap has been defined for some basic AbstractArrays types inside DataFlowTasks. If a specialized method for memory_overlap is not found, DataFlowTasks errs on the safe side and falls back to a generic implementation that always returns true:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using DataFlowTasks: memory_overlap\n\nstruct CirculantMatrix # a custom type\n    data::Vector{Float64}\nend\n\nv = rand(10);\nM = CirculantMatrix(v);\n\nmemory_overlap(M,copy(v))","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The warning message printed above hints at what should be done:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"import DataFlowTasks: memory_overlap\nmemory_overlap(M::CirculantMatrix,v) = memory_overlap(M.data,v) # overload\nmemory_overlap(v,M::CirculantMatrix) = memory_overlap(M,v)\nmemory_overlap(M,v), memory_overlap(M,copy(v))","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"You can now spawn tasks with your custom type CirculantMatrix as a data dependency, and things should work as expected:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using DataFlowTasks\n\nv  = ones(5);\nM1 = CirculantMatrix(v);\nM2 = CirculantMatrix(copy(v));\n\nBase.sum(M::CirculantMatrix) = length(M.data)*sum(M.data)\n\nd1 = @dspawn begin\n    @W v\n    sleep(0.5)\n    fill!(v,0) \nend;\nd2 = @dspawn sum(@R M1)\nd3 = @dspawn sum(@R M2)\n\nfetch(d3) # 25\nfetch(d2) # 0\n\nnothing # hide","category":"page"},{"location":"#Task-graph","page":"Getting started","title":"Task graph","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Each time a Task is spawned using @dspawn, it is added to an internal TaskGraph (see get_active_taskgraph) so that its data-dependencies can be tracked and analyzed. There are two important things to know about TaskGraph objects. First, they are buffered to handle at most sz_max tasks at a time: trying to add a task to the TaskGraph when it is full will block. This is done to keep the cost of analyzing the data dependencies under control. You can modify the buffer size as follows:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using DataFlowTasks # hide\ntaskgraph = DataFlowTasks.get_active_taskgraph()\nresize!(taskgraph,200)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Second, when the computation of a task in the TaskGraph is completed, it gets pushed into a finished channel, to be eventually processed and poped from the graph by the dag_cleaner. This is done to avoid concurrent access to the DAG: only the dag_cleaner should modify it. If you want to stop nodes from being removed from the DAG, you may stop the dag_cleaner using:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"DataFlowTasks.stop_dag_cleaner(taskgraph)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Finished nodes will now remain in the DAG:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"A = ones(5)\n@dspawn begin\n    @RW A\n    A .= 2 .* A\nend\n@dspawn sum(@R A)\ntaskgraph","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Note that stopping the dag_cleaner means finished nodes are no longer removed; since the task graph is a buffered structure, this may cause the execution to halt if it is at full capacity. You can then either resize! it, or simply start the worker (which will result in the processing of the finished channel):","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"DataFlowTasks.start_dag_cleaner(taskgraph)\ntaskgraph","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"tip: Tip\nThere are situations where you may want to use a different TaskGraph temporarily to execute a block of code, and restore the default after. This can be done using the with_taskgraph method.","category":"page"},{"location":"#Limitations","page":"Getting started","title":"Limitations","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Some current limitations are listed below:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"There is no way to specify priorities for a task.\nThe main thread executes tasks, and is responsible for adding/removing nodes from the DAG. This may hinder parallelism if the main thread is given a long task since the processing of the dag will halt until the main thread becomes free again.\n...","category":"page"},{"location":"profiling/#visualization-section","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"DataFlowTasks defines two visualization tools that help when debugging and profiling parallel programs:","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"a visualization of the Directed Acyclic Graph (DAG) internally representing task dependencies;\na visualization of how tasks were scheduled during a run, alongside with other information helping understand what limits the performances of the computation.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"note: Note\nVisualization tools require additional dependencies (such as Makie or GraphViz) which are only needed during the development stage. We are therefore only declaring those as weak dependencies (for Julia v1.9 and above). The user can either set up a stacked environment in which these dependencies are available, or use the DataFlowTasks.stack_weakdeps_env!() function which handles the environment stack automatically.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Let's first introduce a small example that will help illustrate the features introduced here:","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"using DataFlowTasks\nDataFlowTasks.stack_weakdeps_env!() #hide\n\n# Utility functions\ninit!(x)    = (x .= rand())     # Write\nmutate!(x)  = (x .= exp.(x))    # Read+Write\nresult(x,y) = sum(x) + sum(y)   # Read\n\n# Main work function\nfunction work(A, B)\n    # Initialization\n    @dspawn init!(@W(A))               label=\"init A\"\n    @dspawn init!(@W(B))               label=\"init B\"\n\n    # Mutation\n    @dspawn mutate!(@RW(A))            label=\"mutate A\"\n    @dspawn mutate!(@RW(B))            label=\"mutate B\"\n\n    # Final read\n    res = @dspawn result(@R(A), @R(B)) label=\"read A,B\"\n    fetch(res)\nend","category":"page"},{"location":"profiling/#Creating-a-[LogInfo](@ref-DataFlowTasks.LogInfo)","page":"Debugging & Profiling","title":"Creating a LogInfo","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"In order to inspect code which makes use of DataFlowTasks, you can use the DataFlowTasks.@log macro to keep a trace of the various parallel events and the underlying DAG. Note that to avoid profiling the compilation time, it is often advisable to perform a \"dry run\" of the code first, as done in the example below:","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"# Context\nA = ones(2000, 2000)\nB = ones(3000, 3000)\n\n# precompilation run\nwork(copy(A),copy(B)) \n\n# activate logging of events\nlog_info = DataFlowTasks.@log work(A, B)","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"The log_info object above, of LogInfo type, contains information that can be used to reconstruct both the inferred task dependencies, and the parallel execution traces of the DataFlowTasks. A summary of this information can be displayed using DataFlowTasks.describe, as illustrated next:","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"DataFlowTasks.describe(log_info; categories=[\"init\", \"mutate\", \"read\"])","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"More powerful visualization capabilities, such as displaying the underlying DAG or showing the parallel trace of the tasks executed, are available upon loading additional packages such as GraphViz or Makie. These are discussed in the following sections, where we also explain in more detail the meaning of the numbers output by DataFlowTasks.describe.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"warning: Warning\nWhen using @log, you typically want the block of code being benchmarked to wait for the completion of its DataFlowTasks before returning (otherwise the LogInfo object that is returned may lack information regarding the DataFlowTasks that have not been completed). In the example above, that was achieved through the use of fetch in the last line of the work function.","category":"page"},{"location":"profiling/#DAG-visualization","page":"Debugging & Profiling","title":"DAG visualization","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"In order to better understand what this example does, and check that data dependencies were suitably annotated, it can be useful to look at the Directed Acyclic Graph (DAG) representing task dependencies as they were inferred by DataFlowTasks. The DAG can be visualized by creating a GraphViz.Graph out of it:","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"using GraphViz\nGraphViz.Graph(log_info)","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"When the working environment supports rich media, the DAG will be displayed automatically. In other cases, it is possible to export it to an image using DataFlowTasks.savedag:","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"dag = GraphViz.Graph(log_info)\nDataFlowTasks.savedag(\"profiling-example.svg\", dag)\nnothing # hide","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Note how the task labels (which were provided as extra arguments to @dspawn) are used in the DAG rendering and make it more readable. In the DAG visualization, the critical path is highlighted in red: it is the sequential path that took the longest run time during the computation.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"note: Note\nThe run time of this critical path imposes a hard bound on parallel performances: no matter how many threads are available, it is not possible for the computation to take less time than the duration of the critical path.","category":"page"},{"location":"profiling/#Scheduling-and-profiling-information","page":"Debugging & Profiling","title":"Scheduling and profiling information","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"The collected scheduling & profiling information can be visualized using Makie.plot on the log_info object (note that using the GLMakie backend brings a bit more interactivity than CairoMakie):","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"using CairoMakie # or GLMakie to benefit from more interactivity\nplot(log_info; categories=[\"init\", \"mutate\", \"read\"])","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"The categories keyword argument allows grouping tasks in categories according to their labels. In the example above, all tasks containing \"mutate\" in their label will be grouped in the same category.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Note : be careful with giving similar labels. If tasks have \"R\" and \"RW\" labels, and the substrings given to the plot's argument are also \"R\", and \"RW\", then all tasks will be in the category \"R\" (because \"R\" can be found in \"RW\"). Regular expressions can be given instead of substrings in order to avoid such issues.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Let us explore the various parts of this graph.","category":"page"},{"location":"profiling/#Parallel-Trace","page":"Debugging & Profiling","title":"Parallel Trace","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"The main plot (at the top) is the parallel trace visualization. In this example there were two threads; we can see on which thread the task was run, and the time it took.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Even though tasks are grouped in categories by considering substrings in their labels, the full label is shown when hovering over a task in the interactive visualization (i.e. when using GLMakie instead of CairoMakie).","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"The plot also shows the time spent inserting nodes in the graph (which is part of the overhead incurred by the use of DataFlowTasks): these insertion times are visualized as red tasks. They are not visible for such a small example, but the interactive visualization allows zooming on the plot to search for those small tasks.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Also note that inserting tasks into the graph involves memory allocations, and may thus trigger garbage collector sweeps. When this happens, the time spent in the garbage collector is also shown in the plot.","category":"page"},{"location":"profiling/#Run-time:-breakdown-by-activity","page":"Debugging & Profiling","title":"Run time: breakdown by activity","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"A barplot in the bottom left corner of the window gives us information on the break-down of parallel run times (summed over all threads):","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Computing represents the total time spent in the tasks bodies (i.e. \"useful\" work);\nTask Insertion represents the total time spent inserting nodes in the DAG (i.e. overhead induced by DataFlowTasks), possibly including any time spent in the GC if it is triggered by a memory allocation in the task insertion process;\nOther (idle) represents the total idle time on all threads (which may be due to bad scheduling, or simply arise by lack of enough exposed parallelism in the algorithm).","category":"page"},{"location":"profiling/#Elapsed-time-and-bounds","page":"Debugging & Profiling","title":"Elapsed time & bounds","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"A barplot in the bottom center of the window tries to present insightful information about the elapsed (wall-clock) time of the computation, and its limiting factors:","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"Elapsed represents the measured \"wall clock time\" of the computation; it should be larger than both of the bounds described below;\nCritical Path represents the time spent in the longest sequential path in the DAG (shown in red in the DAG visualization). As said above, it bounds the performance in that even infinitely many threads would still have to compute this path sequentially;\nNo-Wait represents the duration of a hypothetical computation in which all computing time would be evenly distributed among threads (i.e. no thread would ever have to wait). This also bounds the total time because it does not account for dependencies between tasks.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"When looking for faster response times, this graph may suggest sensible ways to explore. If the measured time is close to the critical path duration, then adding more threads will be of no help, but decomposing the work in smaller tasks may be useful. On the other hand, if the measured time is close to the \"without waiting\" bound, then adding more workers may reduce the wall clock time and scale relatively well.","category":"page"},{"location":"profiling/#Computing-time:-breakdown-by-category","page":"Debugging & Profiling","title":"Computing time: breakdown by category","text":"","category":"section"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"A barplot in the bottom right of the window displays a break-down of the total computing time (i.e. the total time spent on all threads while performing user-defined tasks), grouped by user-provided category as explained above.","category":"page"},{"location":"profiling/","page":"Debugging & Profiling","title":"Debugging & Profiling","text":"When trying to optimize the sequential performance of the algorithm, this is where one can get data about what actually takes time (and therefore could produce large gains in performance if it could be optimized).","category":"page"}]
}
