var documenterSearchIndex = {"docs":
[{"location":"references.html#references-section","page":"References","title":"References","text":"","category":"section"},{"location":"references.html","page":"References","title":"References","text":"Modules =   [DataFlowTasks]","category":"page"},{"location":"references.html#DataFlowTasks.DataFlowTasks","page":"References","title":"DataFlowTasks.DataFlowTasks","text":"moduel DataFlowTask\n\nCreate Tasks wich keep track of how data flows through it.\n\n\n\n\n\n","category":"module"},{"location":"references.html#DataFlowTasks.LOGGER","page":"References","title":"DataFlowTasks.LOGGER","text":"const LOGGER::Ref{Logger}\n\nGlobal Logger being used to record the events. Can be changed using setlogger!.\n\n\n\n\n\n","category":"constant"},{"location":"references.html#DataFlowTasks.SCHEDULER","page":"References","title":"DataFlowTasks.SCHEDULER","text":"const SCHEDULER::Ref{TaskGraphScheduler}\n\nThe active scheduler being used.\n\n\n\n\n\n","category":"constant"},{"location":"references.html#DataFlowTasks.TASKCOUNTER","page":"References","title":"DataFlowTasks.TASKCOUNTER","text":"const TASKCOUNTER::Ref{Int}\n\nGlobal counter of created DataFlowTasks.\n\n\n\n\n\n","category":"constant"},{"location":"references.html#DataFlowTasks.AccessMode","page":"References","title":"DataFlowTasks.AccessMode","text":"@enum AccessMode READ WRITE READWRITE\n\nDescribe how a DataFlowTask access its data.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.DAG","page":"References","title":"DataFlowTasks.DAG","text":"struct DAG{T}\n\nRepresentation of a directed acyclic graph containing nodes of type T. The list of nodes with edges coming into a node i can be retrieved using inneighbors(dag,i); similarly, the list of nodes with edges leaving from i can be retrieved using outneighbors(dag,i).\n\nDAG is a buffered structure with a buffer of size sz_max: calling addnode! on it will block if the DAG has more than sz_max elements.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.DAG-Union{Tuple{}, Tuple{T}, Tuple{Any}} where T","page":"References","title":"DataFlowTasks.DAG","text":"DAG{T}(sz)\n\nCreate a buffered DAG holding a maximum of s nodes of type T.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.DataFlowTask","page":"References","title":"DataFlowTasks.DataFlowTask","text":"DataFlowTask(func,data,mode)\n\nCreate a task-like object similar to Task(func) which accesses data with AccessMode mode.\n\nWhen a DataFlowTask is created, the elements in its data field will be checked against all other active DataFlowTask to determined if a dependency is present based on a data-flow analysis. The resulting Task will then wait on those dependencies.\n\nA DataFlowTask behaves much like a Julia Task: you can call wait(t), schedule(t) and fetch(t) on it.\n\nSee also: @dtask, @dspawn, @dasync.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.FinishedChannel","page":"References","title":"DataFlowTasks.FinishedChannel","text":"struct FinishedChannel{T} <: AbstractChannel{T}\n\nUsed to store tasks which have been completed, but not yet removed from the underlying DAG. Taking from an empty FinishedChannel will block.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.InsertionLog","page":"References","title":"DataFlowTasks.InsertionLog","text":"struct InsertionLog\n\nLogs the execution trace of a DataFlowTask insertion.\n\nFields:\n\ntime_start  : time the insertion began\ntime_finish : time the insertion finished\ntaskid      : the thread it is inserting\ntid         : the thread on wich the insertion is happening\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.JuliaScheduler","page":"References","title":"DataFlowTasks.JuliaScheduler","text":"struct JuliaScheduler{T} <: TaskGraphScheduler{T}\n\nImplement a simple scheduling strategy which consists of delegating the DataFlowTasks to the native Julia scheduler for execution immediately after the data dependencies have been analyzed using its dag::DAG. This is the default scheduler used by DataFlowTasks.\n\nThe main advantage of this strategy is its simplicity and composability. The main disadvantage is that there is little control over how the underlying Tasks are executed by the Julia scheduler (e.g., no priorities can be passed).\n\nCalling JuliaScheduler(sz) creates a new scheduler with an empty DAG of maximum capacity sz.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.Logger","page":"References","title":"DataFlowTasks.Logger","text":"struct Logger\n\nContains informations on the program's progress. For thread-safety, the Logger structure uses one vector of TaskLog per thread.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.PriorityScheduler","page":"References","title":"DataFlowTasks.PriorityScheduler","text":"struct PriorityScheduler{T} <: TaskGraphScheduler{T}\n\nExecute a DAG by spawning workers that take elements from the runnable channel, execute them, and put them into a finished channel to be processed by a dag_worker.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.RunnableChannel","page":"References","title":"DataFlowTasks.RunnableChannel","text":"struct RunnableChannel <: AbstractChannel{DataFlowTask}\n\nUsed to store tasks which have been tagged as dependency-free, and thus can be executed. The underlying data is stored using a priority queue, with elements with a high priority being popped first.\n\nCalling take on an empty RunnableChannel will block.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.StaticScheduler","page":"References","title":"DataFlowTasks.StaticScheduler","text":"StaticScheduler{T} <: TaskGraphScheduler{T}\n\nLike the JuliaScheduler, but requires an explicit call to execute_dag(ex) to start running the nodes in its dag (and removing them as they are completed).\n\nUsing a StaticScheduler is useful if you wish examine the underling TaskGraph before it is executed.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.Stop","page":"References","title":"DataFlowTasks.Stop","text":"struct Stop\n\nSingleton type used to safely interrupt a task reading from an `AbstractChannel.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.TaskGraph","page":"References","title":"DataFlowTasks.TaskGraph","text":"const TaskGraph = DAG{DataFlowTask}\n\nA directed acyclic graph of DataFlowTasks.\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.TaskGraphScheduler","page":"References","title":"DataFlowTasks.TaskGraphScheduler","text":"abstract type TaskGraphScheduler\n\nStructures implementing a strategy to evaluate a DAG.\n\nConcrete subtypes are expected to contain a dag::DAG field for storing the task graph, and a finished::AbstractChannel field to keep track of completed tasks. The interface requires the following methods:\n\n-spawn(t,sch) -schedule(t,sch)\n\nSee also: JuliaScheduler, PriorityScheduler, StaticScheduler\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.TaskLog","page":"References","title":"DataFlowTasks.TaskLog","text":"struct TaskLog\n\nLogs the execution trace of a DataFlowTask.\n\nFields:\n\ntag         : task id in DAG\ntime_start  : time the task started running\ntime_finish : time the task finished running\ntid         : thread on wich the task ran\ninneighbors : vector of incoming neighbors in DAG\nlabel       : a string used for displaying and/or postprocessing tasks\n\n\n\n\n\n","category":"type"},{"location":"references.html#DataFlowTasks.access_mode-Tuple{DataFlowTasks.DataFlowTask}","page":"References","title":"DataFlowTasks.access_mode","text":"access_mode(t::DataFlowTask[,i])\n\nHow t accesses its data.\n\nSee: AccessMode\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.addedge!-Union{Tuple{T}, Tuple{DataFlowTasks.DAG{T}, T, T}} where T","page":"References","title":"DataFlowTasks.addedge!","text":"addedge!(dag,i,j)\n\nAdd (directed) edge connecting node i to node j in the dag.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.addedge_transitive!-Tuple{Any, Any, Any}","page":"References","title":"DataFlowTasks.addedge_transitive!","text":"addedge_transitive!(dag,i,j)\n\nAdd edge connecting nodes i and j if there is no path connecting them already.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.addnode!-Union{Tuple{T}, Tuple{DataFlowTasks.DAG{T}, T}, Tuple{DataFlowTasks.DAG{T}, T, Any}} where T","page":"References","title":"DataFlowTasks.addnode!","text":"addnode!(dag,(k,v)::Pair[, check=false])\naddnode!(dag,k[, check=false])\n\nAdd a node to the dag. If passed only a key k, the value v is initialized as empty (no edges added). The check flag is used to indicate if a data flow analysis should be performed to update the dependencies of the newly inserted node.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.adjacency_matrix-Union{Tuple{T}, Tuple{DataFlowTasks.DAG{T}}} where T","page":"References","title":"DataFlowTasks.adjacency_matrix","text":"adjacency_matrix(dag)\n\nConstruct the adjacency matrix of dag.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.consume_runnable","page":"References","title":"DataFlowTasks.consume_runnable","text":"consume_runnable(runnable,nt,background=false)\n\nSpawn nt = Threads.nthreads() workers that will consume tasks from runnable and execute them. If background=true the main thread (Threads.threadid()==1) is not used, and only nt-1 tasks are spawned.\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.criticalpath","page":"References","title":"DataFlowTasks.criticalpath","text":"criticalpath(logger) --> path\n\nFinds the critical path of the logger's DAG\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.dagplot","page":"References","title":"DataFlowTasks.dagplot","text":"dagplot(logger=getlogger())\n\nPlot the dag in DOT format\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.data-Tuple{DataFlowTasks.DataFlowTask}","page":"References","title":"DataFlowTasks.data","text":"data(t::DataFlowTask[,i])\n\nData accessed by t.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.data_dependency-Tuple{DataFlowTasks.DataFlowTask, DataFlowTasks.DataFlowTask}","page":"References","title":"DataFlowTasks.data_dependency","text":"data_dependency(t1::DataFlowTask,t1::DataFlowTask)\n\nDetermines if there is a data dependency between t1 and t2 based on the data they read from and write to.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.enable_debug","page":"References","title":"DataFlowTasks.enable_debug","text":"enable_debug(mode = true)\n\nIf mode is true (the default), enable debug mode: errors inside tasks will be shown.\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.enable_log","page":"References","title":"DataFlowTasks.enable_log","text":"enable_log(mode = false)\n\nIf mode=true, information regarding the DataFlowTasks will be logged in the current logger.\n\nSee also: getlogger, setlogger!, TaskLog.\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.execute_dag-Tuple{DataFlowTasks.StaticScheduler}","page":"References","title":"DataFlowTasks.execute_dag","text":"execute_dag(sch::StaticScheduler)\n\nExecute all the nodes in the task graph, removing them from the dag as they are completed. This function waits for the dag to be emptied before returning.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.finished_to_runnable-Tuple{Any, Any, Any}","page":"References","title":"DataFlowTasks.finished_to_runnable","text":"finished_to_runnable(dag,runnable,finished)\n\nWorker which takes nodes from finished, remove them from the dag, and put! new nodes in runnable if they become dependency-free.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.force_sequential","page":"References","title":"DataFlowTasks.force_sequential","text":"force_sequential(mode = true)\n\nIf mode is true, enable sequential mode: no tasks are created and scheduled, code is simply run as it appears in the sources. In effect, this makes @dspawn a no-op.\n\nBy default, sequential mode is disabled when the program starts.\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.getlogger-Tuple{}","page":"References","title":"DataFlowTasks.getlogger","text":"getlogger()\n\nReturn the global logger.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.getscheduler-Tuple{}","page":"References","title":"DataFlowTasks.getscheduler","text":"getscheduler(sch)\n\nReturn the active scheduler.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.has_edge-Tuple{DataFlowTasks.DAG, Any, Any}","page":"References","title":"DataFlowTasks.has_edge","text":"has_edge(dag,i,j)\n\nCheck if there is an edge connecting i to j.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.inneighbors-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.inneighbors","text":"inneighbors(dag,i)\n\nList of predecessors of i in dag.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.isconnected-Tuple{DataFlowTasks.DAG, Any, Any}","page":"References","title":"DataFlowTasks.isconnected","text":"isconnected(dag,i,j)\n\nCheck if there is path in dag connecting i to j.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.loggertodot","page":"References","title":"DataFlowTasks.loggertodot","text":"loggertodot(logger)  --> dagstring\n\nReturn a string in the DOT format representing the underlying graph in logger and to be plotted by GraphViz with Graph(loggertodot())\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.memory_overlap-Tuple{Any, Any}","page":"References","title":"DataFlowTasks.memory_overlap","text":"memory_overlap(di,dj)\n\nDetermine if data di and dj have overlapping memory in the sense that mutating di can change dj (or vice versa). This function is used to build the dependency graph between DataFlowTasks.\n\nA generic version is implemented returning true (but printing a warning). Users should overload this function for the specific data types used in the arguments to allow for appropriate inference of data dependencies.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.memory_overlap-Tuple{Array, Array}","page":"References","title":"DataFlowTasks.memory_overlap","text":"memory_overlap(di::Array,dj::Array)\nmemory_overlap(di::SubArray,dj::Array)\nmemory_overlap(di::Array,dj::SubArray)\n\nWhen both di and dj are Arrays of bitstype, compare their addresses. If one is of type SubArray, compare the parent.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.memory_overlap-Tuple{SubArray, SubArray}","page":"References","title":"DataFlowTasks.memory_overlap","text":"memory_overlap(di::SubArray,dj::SubArray)\n\nFirst compare their parents. If they are the same, compare the indices in the case where the SubArrays have the  same dimension.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.num_edges-Tuple{DataFlowTasks.DAG}","page":"References","title":"DataFlowTasks.num_edges","text":"num_edges(dag::DAG)\n\nNumber of edges in the DAG.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.num_nodes-Tuple{DataFlowTasks.DAG}","page":"References","title":"DataFlowTasks.num_nodes","text":"num_nodes(dag::DAG)\n\nNumber of nodes in the DAG.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.outneighbors-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.outneighbors","text":"outneighbors(dag,i)\n\nList of successors of j in dag.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.plot","page":"References","title":"DataFlowTasks.plot","text":"plot(logger; categories)\n\nPlot DataFlowTasks logger labeled informations with categories.  \n\nEntries in categories define how to group tasks in categories for plotting. Each entry can be:\n\na String: in this case, all tasks having labels in which the string occurs are grouped together. The string is also used as a label for the category itself.\na String => Regex pair: in this case, all tasks having labels matching the regex are grouped together. The string is used as a label for the category itself.\n\nExample\n\nusing CairoMakie\nusing DataFlowTasks\nusing DataFlowTasks: plot, resetlogger!, sync\n\ninit!(A) = (A .= rand())                # Write\nmutate!(A) = (A .= exp.(sum(A).^2).^2)  # Read/Write\nget(A,B) = A+B                          # Read\nfunction work(A, B)\n    @dspawn init!(@W(A))      label=\"init A\"\n    @dspawn init!(@W(B))      label=\"init B\"\n    @dspawn mutate!(@RW(A))   label=\"mutate A\"\n    @dspawn mutate!(@RW(B))   label=\"mutate B\"\n    @dspawn get(@R(A), @R(B)) label=\"read A,B\"\n    sync()\nend\n\n# Context\nA = ones(2000, 2000)\nB = ones(2000, 2000)\n\n# Compilation\n# run your code once to avoid seeing artifacts related to compilation in your logged data\nwork(copy(A), copy(B))\n\n# Start \"real\" profiling work in a clean environment\n# - reset the internal logger state to discard data collected during previous runs\n# - start from a clean memory state. If garbage collection happens during the\n#   run, we'll know it's triggered by the real workload and the visualization will\n#   highlight its impact.\nresetlogger!()\nGC.gc()\n\n# Real Work\nwork(A, B)\n\n# Logger Visualization\nplot(categories=[\"init\", \"read\", \"work on B\" => r\"B$\"])\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.priority-Tuple{DataFlowTasks.DataFlowTask}","page":"References","title":"DataFlowTasks.priority","text":"priority(t::DataFlowTask)\n\nFunction called to determine the scheduled priority of t. The default imlementation simply retuns t.priority.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.remove_node!-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.remove_node!","text":"remove_node!(dag::DAG,i)\n\nRemove node i and all of its edges from dag.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.resetcounter!-Tuple{}","page":"References","title":"DataFlowTasks.resetcounter!","text":"resetcounter!()\n\nReset the TASKCOUNTER to 0.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.resetlogger!","page":"References","title":"DataFlowTasks.resetlogger!","text":"resetlogger(logger=getlogger())\n\nClear the logger's memory, logging states, and reset environnement for new measures.\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.savedag-Tuple{String, GraphViz.Graph}","page":"References","title":"DataFlowTasks.savedag","text":"savedag(filepath, graph)\n\nSave svg dag image in filepath\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.setlogger!-Tuple{DataFlowTasks.Logger}","page":"References","title":"DataFlowTasks.setlogger!","text":"setlogger!(l::Logger)\n\nSet the global (default) logger to l.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.setscheduler!-Tuple{Any}","page":"References","title":"DataFlowTasks.setscheduler!","text":"setscheduler!(r)\n\nSet the active scheduler to r.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.start_dag_worker","page":"References","title":"DataFlowTasks.start_dag_worker","text":"start_dag_worker(sch)\n\nStart a forever-running task associated with sch which takes nodes from finished and removes them from the dag. The task blocks if finished is empty.\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.sync","page":"References","title":"DataFlowTasks.sync","text":"sync([sch::TaskGraphScheduler])\n\nWait for all nodes in sch to be finished before continuining. If called with no arguments, use  the current scheduler.\n\n\n\n\n\n","category":"function"},{"location":"references.html#DataFlowTasks.update_edges!-Tuple{DataFlowTasks.DAG, Any}","page":"References","title":"DataFlowTasks.update_edges!","text":"update_edges!(dag::DAG,i)\n\nPerform the data-flow analysis to update the edges of node i. Both incoming and outgoing edges are updated.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.with_scheduler-Tuple{Any, Any}","page":"References","title":"DataFlowTasks.with_scheduler","text":"with_scheduler(f,sch)\n\nRun f, but push DataFlowTasks to the scheduler dag in sch instead of the default dag.\n\n\n\n\n\n","category":"method"},{"location":"references.html#DataFlowTasks.@dasync-Tuple{Any, Vararg{Any}}","page":"References","title":"DataFlowTasks.@dasync","text":"@dasync expr [kwargs...]\n\nLike @dspawn, but schedules the task to run on the current thread.\n\nSee also:\n\n@dspawn, @dtask\n\n\n\n\n\n","category":"macro"},{"location":"references.html#DataFlowTasks.@dspawn-Tuple{Any, Vararg{Any}}","page":"References","title":"DataFlowTasks.@dspawn","text":"@dspawn expr [kwargs...]\n\nCreate a DataFlowTask to execute the code given by expr, and schedule it to run on any available thread. The code in expr should be annotated with @R, @W and/or @RW tags in order to indicate how it accesses data (see examples below). This information is is then used to automatically infer task dependencies.\n\nSupported keyword arguments:\n\nlabel: provide a label to identify the task. This is useful when logging scheduling information;\npriority: inform the scheduler about the relative priority of the task. This information is not (yet) leveraged by the default scheduler.\n\nSee also:\n\n@dtask, @dasync\n\nExamples:\n\nBelow are 3 equivalent ways to create the same DataFlowTask, which expresses a Read-Write dependency on C and Read dependencies on A and B\n\nusing LinearAlgebra\nA = rand(10, 10)\nB = rand(10, 10)\nC = rand(10, 10)\nα, β = (100.0, 10.0)\n\n# Option 1: annotate arguments in a function call\n@dspawn mul!(@RW(C), @R(A), @R(B), α, β)\n\n# Option 2: specify data access modes in the code block\n@dspawn begin\n   @RW C\n   @R  A B\n   mul!(C, A, B, α, β)\nend\n\n# Option 3: specify data access modes after the code block\n# (i.e. alongside keyword arguments)\n@dspawn mul!(C, A, B, α, β) @RW(C) @R(A,B)\n\nHere is a more complete example, demonstrating a full computation involving 2 different tasks.\n\nusing DataFlowTasks\n\nA = rand(5)\n\n# create a task which writes to A\nt1 = @dspawn begin\n    @W A\n    sleep(1)\n    fill!(A,0)\n    println(\"finished writing\")\nend  label=\"writer\"\n\n# create a task which reads from A\nt2 = @dspawn begin\n    @R A\n    println(\"I automatically wait for `t1` to finish\")\n    sum(A)\nend  priority=1\n\nfetch(t2) # 0\n\n# output\n\nfinished writing\nI automatically wait for `t1` to finish\n0.0\n\nNote that in the example above t2 waited for t1 because it read a data field that t1 accessed in a writable manner.\n\n\n\n\n\n","category":"macro"},{"location":"references.html#DataFlowTasks.@dtask-Tuple{Any, Vararg{Any}}","page":"References","title":"DataFlowTasks.@dtask","text":"@dtask expr [kwargs...]\n\nCreate a DataFlowTask to execute expr, where data have been tagged to specify how they are accessed. Note that the task is not automatically scheduled for execution.\n\nSee @dspawn for information on how to annotate expr to specify data dependencies, and a list of supported keyword arguments.\n\nSee also:\n\n@dspawn, @dasync\n\n\n\n\n\n","category":"macro"},{"location":"examples.html#examples-section","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"TODO: ","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"add a description of the examples and more hardware info\nmention the effects of tilesize ahd capacity on the results of tiled factorization\ncompare 'fork-join' approach to HLU to dataflow approach","category":"page"},{"location":"examples.html#tiledcholesky-section","page":"Examples","title":"Tiled Cholesky factorization","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"The Cholesky factorization algorithm takes a symmetric positive definite matrix A, finds a lower triangular matrix L from a symmetric positive definite matrix A such that A = LLᵀ. The tiled version of this algorithm decompose the matrix A into blocks of even sizes. At each step of the algorithm, we do a Cholesky factorization on the diagonal tile, use a triangular solve to update all of the tiles at the right of the diagonal tile, and finally update all the tiles of the submatrix with a schur complement.","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"We have 3 types of tasks : the cholesky factorization (I), the triangular solve (II), and the schur complement (III).   If we have a matrix A decomposed in n x n tiles, than the algorithm will have n steps. It implies that the step i ∈ [1:n] do 1 time (I), (i-1) times (II), and (i-1)² times (III). So respectively O(n) (I), O(n²) (II), and O(n³) (III). We will compare this result with the \"Times Per Category\" part of the visualization.","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"The code of that algorithm, without parallelization, could be :","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"1   function cholesky!(A::TiledMatrix)\n2       # Number of blocks\n3       m,n = size(A)\n4   \n5       # Core\n6       for i in 1:m\n7           # Diagonal cholesky serial factorization\n8           serial_cholesky!(A[i,i])\n9   \n10          # Left blocks update\n11          L = adjoint(UpperTriangular(Aii))\n12          for j in i+1:n\n13              ldiv!(L,A[i,j])\n14          end\n15  \n16          # Submatrix update\n17          for j in i+1:m\n18              for k in j:n\n19                  Aji = adjoint(A)\n20                  schur_complement!(A[j,k], Aji, A[i,k])\n21              end\n22          end\n23      end\n24  \n25      # Construct the factorized object\n26      return Cholesky(A.data,'U',zero(LinearAlgebra.BlasInt))\n27  end","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"To parallelize this code with DataFlowTasks, we only have to wrap function calls within a @dspawn. We have to change the lines 8, 13, and 20 (as well as add a synchronization point at the end) as follows :","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"8   @dspawn serial_cholesky!(@RW(A[i,i]))\n\n13  @dspawn ldiv!(@R(L), @RW(A[i,j]))\n\n20  @dspawn schur_complement!(@RW(A[j,k]), @R(Aji), @R(A[i,k]))\n\n24  DataFlowTasks.sync()","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"This is implemented in the TiledFactorization package, we give the resulting obtained performances below. ","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"import Pkg\nPkg.add(url=\"https://github.com/maltezfaria/TiledFactorization.git#benchmarking\")","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"using DataFlowTasks\nusing DataFlowTasks: resetlogger!, plot, dagplot\nusing TiledFactorization\nusing TiledFactorization: cholesky!\nusing CairoMakie\nusing LinearAlgebra\n\n# DataFlowTasks environnement setup\nDataFlowTasks.enable_log()\nsch = DataFlowTasks.JuliaScheduler(50)  # optionnal\nDataFlowTasks.setscheduler!(sch)        # optionnal\n\n# Context\ntilesizes = 256\nTiledFactorization.TILESIZE[] = tilesizes\nn = 2048\nA = rand(n, n)\nA = (A + adjoint(A))/2\nA = A + n*I\n\n# Compilation\ncholesky!(copy(A))\n\n# Reset environnement\nresetlogger!()\nGC.gc()\n\n# Real work to be analysed\ncholesky!(A)\n\n# Plot\nplot(categories=[\"chol\", \"ldiv\", \"schur\"])","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"Let's see how we can use this visualization to understand the program and it's progress.","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"We can see the algorithm's progress we described above : the first diagonal tile on which we perform a Cholesky factorization in blue starts it all. Then the triangular solves (in orange) update the tiles at the right of the diagonal tile. After that we have all the green tasks that represent the update of the sub-matrix. We also see how the steps are becoming smaller as the submatrix become smaller. The \"Times per Category\" barplot confirm the repartition we predicted, and hints towards optimising the schur complement part rather than the serial cholesky algorithm.","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"Red tasks represent the time spent inserting nodes in the graph. We specified a capacity of 50 nodes for the scheduler. It means if we have 50 nodes in the DAG, the scheduler will wait until some tasks are finished to insert more nodes in the DAG. If we have to much node in the graph, the algorithm of insertion will cost more. Tests are needed to find the best capacity for each case. Note that the insertion tasks are always handled by the first thread. We see how a lot of tasks are inserted at the beginning. Until it reaches the 50 nodes limit, where it starts working on computing tasks, and after that will go back and forth between computing and inserting.","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"Looking at the plot's \"Activity\" part, and the \"Without Waiting\" bar of the \"Time Bounds\" plot, we can see that only a small percentage of the time is spent waiting. It's in part due to the algorithm, in other part due to the scheduler. To differentiate these causes, the \"Critical Path\" tells us that if we had more cores, we could reach a 2 times speedup. Of course, it will also increase DataFlowTasks' overhead.  ","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"Note : The grey parts of the trace plot don't represent anything : it's the separator between all tasks (so they don't merge). Usually, the insertion tasks are very close to each other, and so there might be a lot a grey, and not that much of red. To avoid that, using GLMakie's interactivity, you can zoom on these parts to see exactly what's happening (the grey parts are adaptative).","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"using DataFlowTasks: dagplot # hide\ndagplot()","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"The more the DAG will be wide, the more it can be paralellized. The more it is thin, the less we are going to benefits from having a lot of cores. In this approach, even if there's a lot of nodes, it can be useful to plot the DAG to see its width. It's a visual complement to the \"Critical Path\" bar in the \"Time Bounds\" plot : the more this bar is small compared to the \"real time\", the more the DAG is wide. But this relation might carry artefacts (like garbage collection time) the DAG's visualization doesn't have.   The DAG can also be used with smaller versions of the algorithm, while in development, to ensure everything is going the way you wanted it to be, or to search for problems.","category":"page"},{"location":"examples.html#Computer-1","page":"Examples","title":"Computer 1","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"(Image: Cholesky 8 cores)","category":"page"},{"location":"examples.html#Computer-2","page":"Examples","title":"Computer 2","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"(Image: Cholesky 20 cores)","category":"page"},{"location":"examples.html#tiledlu-section","page":"Examples","title":"Tiled LU factorization","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"tip: Tip\nSee this page for a discussion on thread-based parallelization of LU factorization.","category":"page"},{"location":"examples.html#[Hierarchical-LU-factorization]","page":"Examples","title":"[Hierarchical LU factorization]","text":"","category":"section"},{"location":"visualization.html#visualization-section","page":"Visualization","title":"Visualization","text":"","category":"section"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The visualization uses 2 main tools : one for plotting the parallel trace and other general information, and another for plotting the DAG :","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"plot(logger=getlogger(); categories)\ndagplot(logger=getlogger())","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"Visualization tools, such as the packages they need, are not loaded by default. We are using Requires.jl, that allows us to ignore this part of DataFlowTasks when not needed. For example, when finished developing your package using DataFlowTasks, visualization tools won't be necessary. This way you won't carry useless code and packages.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"So the first step to visualization will be to load the packages that will trigger the code loading.   Again, 2 packages related to the 2 different visualizations : one of Makie backend for the general plot, and GraphViz for the dagplot.   The next lines will load all of the visualization tools, and enable logging :","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"using CairoMakie, GraphViz\r\nusing DataFlowTasks\r\n\r\nDataFlowTasks.enable_log()","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"Note: choosing GLMakie over CairoMakie will bring a bit of interactivity.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"Let's illustrate the usage with a small example. Functions we'll be working with are written below.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"using CairoMakie, GraphViz\r\nusing DataFlowTasks\r\nusing DataFlowTasks: plot\r\n\r\n# Utility functions\r\ninit!(A) = (A .= rand())                # Write\r\nmutate!(A) = (A .= exp.(sum(A).^2).^2)  # Read/Write\r\nget(A,B) = A+B                          # Read\r\n\r\n# Main work function\r\nfunction work(A, B)\r\n    # Initialization\r\n    @dspawn init!(@W(A))\r\n    @dspawn init!(@W(B))\r\n\r\n    # Mutation\r\n    @dspawn mutate!(@RW(A))\r\n    @dspawn mutate!(@RW(B)) \r\n\r\n    # Final read\r\n    @dspawn get(@R(A), @R(B))\r\n\r\n    DataFlowTasks.sync()\r\nend","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"Usually, when wanting to visualize the parallelization, you should do as follows :","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"# Context\r\nA = ones(2000, 2000)\r\nB = ones(2000, 2000)\r\n\r\n# Compilation\r\n# run your code once to avoid seeing artifacts related to compilation in your logged data\r\nwork(copy(A), copy(B))\r\n\r\n# Start \"real\" profiling work in a clean environment\r\n# - reset the internal logger state to discard data collected during previous runs\r\n# - start from a clean memory state. If garbage collection happens during the\r\n#   run, we'll know it's triggered by the real workload and the visualization will\r\n#   highlight its impact.\r\nresetlogger!()\r\nGC.gc()\r\n\r\n# Real Work\r\nwork(A, B)","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The logger will get informations on the final call to work, the visualization is a post-processing of these data. We have finally :","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"using CairoMakie, GraphViz\r\nusing DataFlowTasks\r\nusing DataFlowTasks: plot, dagplot, resetlogger!\r\n\r\nDataFlowTasks.enable_log()\r\n\r\n\r\n# Utility functions\r\ninit!(A) = (A .= rand())                # Write\r\nmutate!(A) = (A .= exp.(sum(A).^2).^2)  # Read/Write\r\nget(A,B) = A+B                          # Read\r\n\r\n# Main work function\r\nfunction work(A, B)\r\n    # Initialization\r\n    @dspawn init!(@W(A))        label = \"init A\"\r\n    @dspawn init!(@W(B))        label = \"init B\"\r\n\r\n    # Mutation\r\n    @dspawn mutate!(@RW(A))     label = \"mutate A\"\r\n    @dspawn mutate!(@RW(B))     label = \"mutate B\"\r\n\r\n    # Final read\r\n    @dspawn get(@R(A), @R(B))   label = \"read A,B\"\r\n\r\n    DataFlowTasks.sync()\r\nend\r\n\r\n# Context\r\nA = ones(2000, 2000)\r\nB = ones(2000, 2000)\r\n\r\n# Compilation\r\n# run your code once to avoid seeing artifacts related to compilation in your logged data\r\nwork(copy(A), copy(B))\r\n\r\n# Start \"real\" profiling work in a clean environment\r\n# - reset the internal logger state to discard data collected during previous runs\r\n# - start from a clean memory state. If garbage collection happens during the\r\n#   run, we'll know it's triggered by the real workload and the visualization will\r\n#   highlight its impact.\r\nresetlogger!()\r\nGC.gc()\r\n\r\n# Real Work\r\nwork(A, B)","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"using DataFlowTasks: plot # hide\r\nplot(categories=[\"init\", \"mutate\", \"read\"])","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"and the DAG's plot :","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"using DataFlowTasks: dagplot # hide\r\ndagplot()","category":"page"},{"location":"visualization.html#Parallel-Trace","page":"Visualization","title":"Parallel Trace","text":"","category":"section"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The main plot is the parallel trace visualization. We can see on which thread the task was run, and the time it took.   It also shows the time spent inserting nodes in the graph (DataFlowTasks' overhead), considered also in the plot as tasks, represented in red. Here there aren't a lot of tasks, so the insertion tasks aren't really visible. Using GLMakie allows zooming on the plot to search for those small tasks. If the garbage collector is run while the work is ongoing, it will be shown in the plot.  ","category":"page"},{"location":"visualization.html#Labels","page":"Visualization","title":"Labels","text":"","category":"section"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"We see we can label our tasks for the plot to be clearer and to carry more information, although it is not necessary : a call to plot() without arguments, or not specifying labels on tasks creations, is absolutely possible.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The labels given to the categories plot's argument work as substrings : if a task's label is \"work on A\", and the label given in categories is \"work\", because the substring can be found in the task label, it will go in that category.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The longer label isn't useless though. When using GLMakie, the plot will be a little more interactive : when hovering on a task trace, under the plot's title will be written the full task label. Also, the nodes' names of the DAG's plot will be those task labels, as we can see above.","category":"page"},{"location":"visualization.html#Activity-plot","page":"Visualization","title":"Activity plot","text":"","category":"section"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"This barplot gives us information on the parallelization results.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"Computing will be the time spent doing the work given by the user in the tasks.\nInserting will be the time spent inserting nodes in the DAG (DataFlowTasks' overhead), it also carries the garbage collector time when it's called.\nOther represents the time waiting.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"All those times are cumulative of all threads.","category":"page"},{"location":"visualization.html#Time-Bounds","page":"Visualization","title":"Time Bounds","text":"","category":"section"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"We give post-processed time bounds to give additional information on the parallelization.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The critical path, which is the red path in the DAG's plot (see above), is the sum of the duration of the tasks constituting the critical path. It means that even if we had an infinite number of cores, we couldn't exceed this time because of the algorithm.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The without waiting post-processed time gives the time it would have taken if we hadn't waited at all (it's the sum of all of the task's duration divided by the number of threads).","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"We can't have a smaller time than those 2 boundaries.","category":"page"},{"location":"visualization.html#Times-per-Category","page":"Visualization","title":"Times per Category","text":"","category":"section"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"As discussed above, if a task has a substring given in the plot's argument in its label, then the task will be associated with this substring. For example : the task \"init A\" will go in the category \"init\".","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"The times represented by the barplot are the sum of the task's duration for each category.","category":"page"},{"location":"visualization.html","page":"Visualization","title":"Visualization","text":"Note : be careful with giving similar labels. If tasks have \"R\" and \"RW\" labels, and the substrings given to the plot's argument are also \"R\", and \"RW\", then all tasks will be in the category \"R\" (because \"R\" can be found in \"RW\"). The \"RW\" will be right though.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"CurrentModule = DataFlowTasks","category":"page"},{"location":"index.html#DataFlowTasks","page":"Getting started","title":"DataFlowTasks","text":"","category":"section"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"Tasks which automatically respect data-flow dependencies","category":"page"},{"location":"index.html#Basic-usage","page":"Getting started","title":"Basic usage","text":"","category":"section"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"This package defines a DataFlowTask type which behaves very much like a Julia Task, except that it allows the user to specify explicit data dependencies. This information is then be used to automatically infer task dependencies by constructing and analyzing a directed acyclic graph based on how tasks access the underlying data. The premise is that it is sometimes simpler to specify how tasks depend on data than to specify how tasks depend on each other.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"The use of a DataFlowTask is intended to be as similar to a native Task as possible. The API revolves around three macros:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"@dtask\n@dspawn\n@dasync","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"They behave like their Base counterparts (@task, Threads.@spawn and @async), but additional annotations specifying explicit data dependencies are required. The example below shows the most basic usage:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks # hide\n\nA = ones(5)\nB = ones(5)\nd = @dspawn begin\n    @RW A   # A is accessed in READWRITE mode\n    @R  B   # B is accessed in READ mode\n    A .= A .+ B\nend\n\nfetch(d)","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"This creates (and schedules for execution) a DataFlowTask d which accesses A in READWRITE mode, and B in READ mode. The benefit of DataFlowTasks comes when you start to compose operations which may mutate the same data:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks # hide\n\nn = 100_000\nA = ones(n)\n\nd1 = @dspawn begin\n    @RW A\n\n    # in-place work on A\n    for i in eachindex(A)\n        A[i] = log(A[i]) # A[i] = 0\n    end\nend\n\n# reduce A\nd2 = @dspawn sum(@R A)\n# The above is a shortcut for:\n#   d2 = @dspawn begin\n#       @R A\n#       sum(A)\n#   end\n\n\nc = fetch(d2) # 0","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"We now have two asynchronous tasks being created, both of which access the array A. Because d1 writes to A, and d2 reads from it, the outcome C is nondeterministic unless we specify an order of precedence. DataFlowTasks reinforces the sequential consistency criterion, which is to say that executing tasks in parallel must preserve, up to rounding errors, the result that would have been obtained if they were executed sequentially (i.e. d1 is executed before d2, d2 before d3, and so on). In this example, this means d2 will always wait on d1 because of an inferred data dependency. The outcome is thus always zero.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"note: Note\nIf you replace @dspawn by Threads.@spawn in the example above (and pick an n large enough) you will see that you no longer get 0 because d2 may access an element of A before it has been replaced by zero!","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"tip: Tip\nIn the d2 example above, a shortcut syntax was introduced, which allows putting READ/WRITE annotations directly around arguments in a function call. This is especially useful when the task body is a one-liner.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"No parallelism was allowed in the previous example due to a data conflict. To see that when parallelism is possible, spawning DataFlowTasks will exploit it, consider this one last example:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks # hide\n\nn = 100\nA = ones(n)\n\nd1 = @dspawn begin\n    @W A\n\n    # write to A\n    sleep(1)\n    fill!(A,0)\nend\n\nd2 = @dspawn begin\n    @R A\n\n    # some long computation \n    sleep(5)\n    # reduce A\n    sum(A)\nend\n\n# another reduction on A\nd3 = @dspawn sum(x->sin(x), @R(A))\n\nt = @elapsed c = fetch(d3)\n\nt,c ","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"We see that the elapsed time to fetch the result from d3 is on the order of one second. This is expected since d3 needs to wait on d1 but can be executed concurrently with d2. The result is, as expected, 0.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"All examples this far have been simple enough that the dependencies between the tasks could have been inserted by hand. There are certain problems, however, where the constant reuse of memory (mostly for performance reasons) makes a data-flow approach to parallelism a rather natural way to implicitly describe task dependencies. This is the case, for instance, of tiled (also called blocked) matrix factorization algorithms, where task dependencies can become rather difficult to describe in an explicit manner. The tiled factorization section showcases some non-trivial problems for which DataFlowTasks may be useful.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"tip: Tip\nThe main goal of DataFlowTasks is to expose parallelism: two tasks ti and tj can be executed concurrently if one does not write to memory that the other reads. This data-dependency check is done dynamically, and therefore is not limited to tasks in the same lexical scope. Of course, there is an overhead associated with these checks, so whether performance gains can be obtained depend largely on how parallel the algorithm is, as well as how long each individual task takes (compared to the overhead).","category":"page"},{"location":"index.html#Custom-types","page":"Getting started","title":"Custom types","text":"","category":"section"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"In order to infer dependencies between DataFlowTasks, we must be able to determine whether two objects A and B share a common memory space. That is to say, we must know if mutating A can affect B, or vice-versa. Obviously, without any further information on the types of A and B, this is an impossible question.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"To get around this challenge, you must import and extend the memory_overlap method to work on any pair of elements A and B that you wish to use. The examples in the previous section worked because these methods have been defined for some basic AbstractArrays:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks: memory_overlap\n\nA = rand(10,10)\nB = view(A,1:10)\nC = view(A,11:20)\n\nmemory_overlap(A,B),memory_overlap(A,C),memory_overlap(B,C)","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"By default, memory_overlap will return true and print a warning if it does not find a specialized method:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks: memory_overlap\n\nstruct CirculantMatrix\n    data::Vector{Float64}\nend\n\nv = rand(10);\nM = CirculantMatrix(v);\n\nmemory_overlap(M,copy(v))","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"Extending the memory_overlap will remove the warning, and produce a more meaningful result:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"import DataFlowTasks: memory_overlap\n\n# overload the method\nmemory_overlap(M::CirculantMatrix,v) = memory_overlap(M.data,v)\nmemory_overlap(v,M::CirculantMatrix) = memory_overlap(M,v)\n\nmemory_overlap(M,v), memory_overlap(M,copy(v))","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"You can now spawn tasks with your custom type CirculantMatrix as a data dependency, and things should work as expected:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks\n\nv  = ones(5);\nM1 = CirculantMatrix(v);\nM2 = CirculantMatrix(copy(v));\n\nBase.sum(M::CirculantMatrix) = length(M.data)*sum(M.data)\n\nd1 = @dspawn begin\n    @W v\n    sleep(0.5)\n    fill!(v,0) \nend;\nd2 = @dspawn sum(@R M1)\nd3 = @dspawn sum(@R M2)\n\nfetch(d3) # 25\n\nfetch(d2) # 0","category":"page"},{"location":"index.html#Scheduler","page":"Getting started","title":"Scheduler","text":"","category":"section"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"When loaded, the DataFlowTasks package will initialize an internal scheduler (of type JuliaScheduler), running on the background, to handle implicit dependencies of the spawned DataFlowTasks. In order to retrieve the current scheduler, you may use the getscheduler method:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks # hide\nDataFlowTasks.sync() # hide\nsch = DataFlowTasks.getscheduler()","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"The default scheduler can be changed through setscheduler!.","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"There are two important things to know about the default JuliaScheduler type. First, it contains a buffered dag that can handle up to sz_max nodes: trying to spawn a task when the dag is full will block. This is done to keep the cost of analyzing the data dependencies under control, and it means that a full/static dag may in practice never be constructed. You can modify the buffer size as follows:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"resize!(sch.dag,50)","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"Second, when the computation of a DataFlowTask ti is completed, it gets pushed into a finished channel, to be eventually processed and poped from the dag by the dag_worker. This is done to avoid concurrent access to the dag: only the dag_worker should modify it. If you want to stop nodes from being removed from the dag, you may stop the dag_worker using:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"DataFlowTasks.stop_dag_worker(sch)","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"Finished nodes will now remain in the dag:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"using DataFlowTasks: R,W,RW, num_nodes\nA = ones(5)\n@dspawn begin \n    @RW A\n    A .= 2 .* A\nend\n@dspawn sum(@R A)\nsch","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"Note that stopping the dag_worker means finished nodes are no longer removed from the dag; since the dag is a buffered structure, this may cause the execution to halt if the dag is at full capacity. You can then either resize! it, or simply start the worker (which will result in the processing of the finished channel):","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"DataFlowTasks.start_dag_worker(sch)\nsch","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"tip: Tip\nThere are situations where you may want to change the default scheduler temporarily to execute a block of code, and revert to the default scheduler after. This can be done using the with_scheduler method. ","category":"page"},{"location":"index.html#Logging","page":"Getting started","title":"Logging","text":"","category":"section"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"TODO","category":"page"},{"location":"index.html#Limitations","page":"Getting started","title":"Limitations","text":"","category":"section"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"Some current limitations are listed below:","category":"page"},{"location":"index.html","page":"Getting started","title":"Getting started","text":"At present, errors are rather poorly handled. The only way to know if a task has failed is to manually inspect the dag\nThere is no way to specify priorities for a task.\nThe main thread executes tasks, and is responsible for adding/removing nodes from the dag. This may hinder parallelism if the main thread is given a long task since the processing of the dag will halt until the main thread becomes free again.\n...","category":"page"},{"location":"dagger.html#dagger-section","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"","category":"section"},{"location":"dagger.html#What's-Dagger.jl","page":"Comparaison with Dagger.jl","title":"What's Dagger.jl","text":"","category":"section"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Dagger is a package for parallel computing, inspired by Python's Dask library, that is meant to be flexible and easy to use. It's supposed to help the parallelization of a complex serial code without the need to refactor everything. It uses a functionnal paradigm to easily imply dependencies between tasks, so they are not to be thought by the user. An exemple from Dagger.jl's documentation :  ","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"using Dagger\n\nadd1(value) = value + 1\nadd2(value) = value + 2\ncombine(a...) = sum(a)\n\np = Dagger.@spawn add1(4)\nq = Dagger.@spawn add2(p)\nr = Dagger.@spawn add1(3)\ns = Dagger.@spawn combine(p, q, r)\n\n@assert fetch(s) == 16","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"The result of the first task will be stored in p, and Dagger detects that q needs p to run, etc.. So the dependencies are automatically computed, and give the next DAG :  ","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"(Image: Dagger's DAG)  ","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Under the hood, what's happening is we don't manipulate numbers, and matrices, but EagerThunks. After the fisrt line, p has become an EagerThunk, a sort of task carrying all the informations needed by Dagger.","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Because we now know the dependencies between all tasks, we can give that to a scheduler (Dagger.jl implements his own), and give those tasks to different cores.","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Dagger.jl's abstraction handles multi-threading and distributed parallel computing.","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Like Dask, Dagger.jl comes with it's own data structures, mainly DArrays, for distributed memory computing.","category":"page"},{"location":"dagger.html#Comparison","page":"Comparaison with Dagger.jl","title":"Comparison","text":"","category":"section"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"The main points that separate working with DataFlowTasks and Dagger are :","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"The approach : dependencies are not implied by variable names, but by variable's associated memory.\nData structure : data structures are not wrapped into a package's own data structure (EagerThunk).\nDistributed parallelism : not supported by DataFlowTasks. \nDagger use a functionnal paradigm.\nScheduler : Dagger has it's own scheduler, where DataFlowTasks uses Julia's default one.\nPerformances (see below)","category":"page"},{"location":"dagger.html#Case-study","page":"Comparaison with Dagger.jl","title":"Case study","text":"","category":"section"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"DataFlowTasks is oriented towards linear algebra matrix computations, let's see how it can be prefered as Dagger.jl in that case by looking at the cholesky tiled factorization algorithm. We'll consider our matrix A already divided in blocks, where Aij is a view of the block at index (i,j).   The pseudo-code for this algorithm would be :","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Requires : A of size m*n \nfor i in 1:m\n    Aii <- cholesky(Aii)\n    for j in i+1:m\n        Aij <- ldiv(Aii,Aij)\n    end\n    for j in i+1:m\n        for k in j:n\n            Ajk <- schurcomplement(Ajk, Aji, Aik)\n        end\n    end\nend","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"In the first place, we can see that Dagger.jl's functionnal paradigm behaves like what we are used to write in pseudo-code : Aii <- cholesky(Aii). Usually though, code would written like : cholesky!(Aii), the function modifying the variable.  ","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"The problem here is that in this code, we'll only use a couple of variables names : Aii, Aij, Ajk etc... that will represent, depending on the iteration, a different matrix block.   To illustrate :","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"p = Dagger.@spawn add1(4)\np = Dagger.@spawn add2(2)\nq = Dagger.@spawn add1(p)","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Here the first task is shadowed by second, q will only wait for the second task.   Therefore in the cholesky tiled factorization, we have to have a single variable name for every block of memory. Before computing anything we have to change our paradigm : we can't manipulate blocks of memory, we have to manipulate Eagerthunks previously mapped to blocks of memory.","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"# Map thunks to blocks of memory\nthunks = Matrix{Dagger.EagerThunk}(undef, m, n)\n# ...\n\n# Work on thunks\nfor i in 1:m\n    thunks[i, i] = Dagger.@spawn cholesky(thunks[i, i])\n    # ...\nend\n\n# Reverse mapping from thunks to blocks of memory\nfor i in 1:m, j in i:n\n    Aij .= fetch(thunks[i, j])\nend","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"It can be more natural to reason on memory access, rather than on return values stored by variables. The DataFlowTasks cholesky tiled factorization would look more similar to the common pseudo-code showed above :","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"for i in 1:m\n    @dpsawn cholesky!(@RW(Aii))\n    for j in i+1:m\n        @dspawn ldiv!(@R(L), @RW(Aij))\n    end\n    for j in i+1:m\n        for k in j:n\n            @dspawn matmul!(@RW(Ajk), @R(Aji), @R(Aik))\n        end\n    end\nend","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"With DataFlowTasks, the approach is thinking in an isolated way, at the moment of writing the function call, what are the modes of access of the variables. There's no need to take the whole code into account.","category":"page"},{"location":"dagger.html#Write-After-Read","page":"Comparaison with Dagger.jl","title":"Write After Read","text":"","category":"section"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Dagger.jl doesn't detect this kind of dependcies (WAR). Although it's not the most common type of depency, it's still worth noticing. Let's look at a simple example.","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Let a vector of 4 elements X = ones(4), with 2 views X₁ = @views X[1:2] and X₂ = @views X[3:4]. We reproduce here the behaviour of the data structures we used in the cholesky tiled factorization exemple. We will use the 2 next functions to work on this data structure.","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"function longTask(Xᵢ...)\n    sleep(2)\n    Xᵢ[1] .*= (2.0 .+ Xᵢ[2])\nend\nfunction shortTask(Xᵢ...)\n    Xᵢ[1] .+= 1.0\nend","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"The work we want to do will be of type : RW(X₁) -> RW(X₂) R(X₁) -> RW(X₁), and we will name those 3 tasks tᵢ with i ∈ [1, 2, 3]. The code will be :","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"X₁ = Dagger.@spawn shortTask(X₁)\nX₂ = Dagger.@spawn longTask(X₂, X₁)\n# fetch(X₂) needs to be added if we want it to work\nX₁ = Dagger.@spawn shortTask(X₁)\n\nfetch(X₁)\nfetch(X₂)\nX","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"We could think that because X₁ is in argument in t₂, when we'll want to write on X₁ in t₃, we will wait for t₂ to be finished. If it's the case, will have the following stats for X (the middle bar represent the separation X₁ and X₂ induce) :","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"1 1 | 1 1\n2 2 | 1 1  --> t₁\n1 1 | 4 4  --> t₂\n3 3 | 4 4  --> t₃","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Instead if we don't wait for t₂, we'll have an inversion of t₃ and t₂. We will have :","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"1 1 | 1 1\n2 2 | 1 1  --> t₁\n3 3 | 1 1  --> t₃\n3 3 | 5 5  --> t₂","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"Actually, it's the case when the tasks are meant to be of different times like they are now (to illustrate the point). If they are not so different with each other, the code becomes non-determinstic.","category":"page"},{"location":"dagger.html","page":"Comparaison with Dagger.jl","title":"Comparaison with Dagger.jl","text":"!!! TO DO : PERFORMANCE DIFFERENCES !!!","category":"page"}]
}
